{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Paramecium cell shape analysis from IF experiments**\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted from the cell mask pipeline of Benedetta Noferi.\n",
    "\n",
    "Input:\n",
    "- .nd2 files from the IF experiments put together in a single folder (folder_path)\n",
    "\n",
    "Explanation workflow:\n",
    "- The code takes as an input the TIF images obtained through a macro of imageJ, that already opens the `.nd2` files, obtains the metadata and creates (and saves) a maximum projection from the centrin channel (second channel) of each image to use for extracting the shape parameters.\n",
    "- (If needed, different cell types can be put into different categories automatically using the image name.)\n",
    "- The max projection of the centrin channel is blurred by a gaussian filter before thresholded using Otsu. Regionprops is then used to filter out wrong shapes and measure the size and shape of all cells. Filtered thresholded images are saved. Shape parameters are saved in a csv file and plotted in the jupyter notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import nd2\n",
    "import os\n",
    "import re\n",
    "import pims\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from skimage import measure\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.patches as patches\n",
    "from scipy.ndimage import binary_closing\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from microfilm import colorify\n",
    "import tifffile as tiff\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functions_shape_analysis import *  \n",
    "\n",
    "\n",
    "# Path to folder that contains the .nd2 files\n",
    "folder_path = \"W:\\\\Users\\\\Daphne\\\\Imaging_Daphne\\\\25-06-25_XC_ptetwt_IF\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **.nd2 import and z-projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplegroup, centrin, dna = import_and_classify_nd2_files_2ch(folder_path) # 2 channels\n",
    "# samplegroup, centrin, polye, dna = import_and_classify_nd2_files(folder_path) # 3 channels\n",
    "display_multichannel_samplegroup(samplegroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 channel images: Data loading and visualization with scale bar\n",
    "display_multichannel_samplegroup_2ch(samplegroup)\n",
    "\n",
    "# # 3 channel images: Data loading and visualization with scale bar\n",
    "# samplegroup, centrin, polye, dna = import_and_classify_nd2_files(folder_path)\n",
    "# display_multichannel_samplegroup(samplegroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the sample groups (different cell types (one or more)) and for each sample group the image files with their calibration and image shape (x,y)\n",
    "centringroup = centrin\n",
    "# centringroup = polye # if the order of the channels is different, you can use polye or dna \n",
    "# centringroup = dna # if the order of the channels is different, you can use polye or dna\n",
    "print(\"Samplegroup:\", centringroup.keys())\n",
    "\n",
    "#Optional: display the dictionary as a the set of filename, image, calibration\n",
    "for sample in centringroup:\n",
    "    print(f\"Sample: {sample}\")\n",
    "    for filename, image, calibration in centringroup[sample]:\n",
    "        print(f\"  Filename: {filename}, Calibration: {calibration}, Image shape: {image.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tif of centrin maximum projection in Z**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once classified them according to the type, we can open them and display them (with the scale)\n",
    "# Call the function to display the images\n",
    "display_samplegroup_with_scale(centringroup, calibration)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image pre-processing for cell masking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the creation of the mask we first apply a broad Gaussian blurring, followed but an Otsu thresholding and filling the holes. The initial data is the maximum projection of the centrin channel showing the cell shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian blurring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian blurring, i.e. Smoothing of the image for a better thresholding\n",
    "sigma = 10\n",
    "gaussian_blur = apply_function_to_samplegroup(centringroup, gaussian, sigma=sigma)\n",
    "\n",
    "# Display the processed images\n",
    "display_samplegroup(gaussian_blur)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Otsu threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the thresholded images\n",
    "Otsu_threshold = {}\n",
    "# Apply otsu's threshold to the images of the gaussian_blur dictionary\n",
    "for sample, files in gaussian_blur.items():\n",
    "    for filename, centrin, calibration in files:\n",
    "        # Apply OTSU's threshold to the image\n",
    "        thresh = threshold_otsu(centrin)\n",
    "        centrin_thresholded = centrin > thresh*1.1 #VARY PER SAMPLE\n",
    "        # Binary closure (not fundamental at this point, but good procedure)\n",
    "        centrin_smoothed = binary_closing(centrin_thresholded, structure=np.ones((3, 3)))\n",
    "        # Update the image in the dictionary\n",
    "        if sample not in Otsu_threshold:\n",
    "            Otsu_threshold[sample] = []\n",
    "        Otsu_threshold[sample].append((filename, centrin_smoothed, calibration))\n",
    "\n",
    "# Call the function to display the images\n",
    "display_samplegroup(Otsu_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filling holes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filled_holes = apply_function_to_samplegroup(Otsu_threshold, ndi.binary_fill_holes)\n",
    "\n",
    "# Call the function to display the images\n",
    "display_samplegroup(Filled_holes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label each cell from 0 to N cells in the region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_images = {}\n",
    "\n",
    "# Iterate over the Filled_holes dictionary\n",
    "for sample, files in Filled_holes.items():\n",
    "    for filename, centrin_filled, calibration in files:\n",
    "        # Label the regions in the image\n",
    "        centrin_labeled, num_features = ndi.label(centrin_filled)\n",
    "        \n",
    "        # Store the labeled image and the number of features in the new dictionary\n",
    "        if sample not in masked_images:\n",
    "            masked_images[sample] = []\n",
    "        masked_images[sample].append((filename, centrin_labeled, num_features, calibration))\n",
    "\n",
    "# Example usage with the filtered labeled images\n",
    "display_samplegroup_with_legend(masked_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering of the regions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calculating the cell shape parameters using regionprops, we filter out noise (using minimum area) and remove the cells that are attached to the border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dictionary to store the filtered masked images\n",
    "masked_filtered_images = {}\n",
    "\n",
    "    \n",
    "# Iterate over the masked_images dictionary\n",
    "area_threshold = 50000  # Set the minimum area threshold\n",
    "for sample, files in masked_images.items():\n",
    "    for filename, labeled_image, num_features, calibration in files:\n",
    "\n",
    "        space = (1/calibration, 1/calibration)  # Set the spacing for regionprops\n",
    "\n",
    "        regions = measure.regionprops(labeled_image, spacing=space)  # Get the regions from the labeled image\n",
    "        \n",
    "        # Get image dimensions\n",
    "        image_height, image_width = labeled_image.shape\n",
    "\n",
    "        # Filter regions based on the area threshold and border condition\n",
    "        filtered_regions = [\n",
    "            region for region in regions\n",
    "            if region.area * (calibration ** 2) >= area_threshold and\n",
    "            region.bbox[0] >= 2 and region.bbox[1] >= 2 and  # Ensures that the region is not too close to the top and left borders\n",
    "            region.bbox[2] <= image_height * 0.999 and region.bbox[3] <= image_width * 0.999  # Ensures that the region is not too close to the bottom and right borders\n",
    "        ]\n",
    "\n",
    "        # Create a new labeled image for the filtered regions\n",
    "        filtered_labeled_image = np.zeros_like(labeled_image)\n",
    "        for new_label, region in enumerate(filtered_regions, start=1):\n",
    "            filtered_labeled_image[labeled_image == region.label] = new_label\n",
    "\n",
    "        # Store the filtered labeled image in the new dictionary\n",
    "        if sample not in masked_filtered_images:\n",
    "            masked_filtered_images[sample] = []\n",
    "        masked_filtered_images[sample].append((filename, filtered_labeled_image, len(filtered_regions), calibration))\n",
    "\n",
    "# Call the function to display the filtered labeled images\n",
    "display_samplegroup_with_labels(masked_filtered_images)\n",
    "\n",
    "# save the filtered labeled images to a new folder\n",
    "output_folder = os.path.join(folder_path, \"Filtered_Labeled_Images\")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "import tifffile as tiff\n",
    "for sample, files in masked_filtered_images.items():\n",
    "    for filename, filtered_labeled_image, num_features, calibration in files:\n",
    "        # Create a new filename for the filtered labeled image\n",
    "        new_filename = os.path.join(output_folder, f\"{filename[:-4]}.tif\")\n",
    "        \n",
    "        # Save the filtered labeled image as a TIFF file\n",
    "        tiff.imwrite(new_filename, filtered_labeled_image.astype(np.uint16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put the regions measurements in a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the properties\n",
    "data = {\n",
    "    'Sample': [],\n",
    "    'Number Within Sample': [],\n",
    "    'Filename': [],\n",
    "    'Label': [],\n",
    "    'Area': [],\n",
    "    'Major Axis Length': [],\n",
    "    'Minor Axis Length': [],\n",
    "    'Aspect Ratio': []\n",
    "}\n",
    "\n",
    "# Iterate over the masked_filtered_images dictionary\n",
    "for sample, files in masked_filtered_images.items():\n",
    "    for file_index, (filename, labeled_image, num_features, calibration) in enumerate(files):\n",
    "        # Calculate region properties\n",
    "        regions = measure.regionprops(labeled_image)\n",
    "        \n",
    "        # Populate the DataFrame with region properties\n",
    "        for region in regions:\n",
    "            data['Sample'].append(sample)\n",
    "            data['Number Within Sample'].append(file_index + 1)\n",
    "            data['Filename'].append(filename)\n",
    "            data['Label'].append(region.label)\n",
    "            data['Area'].append(region.area * (calibration ** 2))\n",
    "            data['Major Axis Length'].append(region.major_axis_length * calibration)\n",
    "            data['Minor Axis Length'].append(region.minor_axis_length * calibration)\n",
    "            data['Aspect Ratio'].append(region.major_axis_length / region.minor_axis_length)\n",
    "\n",
    "# Convert the dictionary to a Pandas DataFrame\n",
    "df_data = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file for later analysis\n",
    "df_data.to_csv(folder_path + 'region_properties.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data visualization for different samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the sample groups with the mean properties\n",
    "\n",
    "mean_properties = calculate_mean_properties(masked_filtered_images)\n",
    "display_samplegroup_with_mean_properties(masked_filtered_images, mean_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data analysis from regionprops**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The cell area\n",
    "- The cell major and minor axis length (fit as an ellipse), including the aspect ratio\n",
    "- The cell eccentricity (eccentricity of the ellipse that has the same second moments as the region)\n",
    "- The cell solidity, (the area of the region / area of the convex hull of the region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the masked_filtered_images dictionary into a DataFrame for easier plotting\n",
    "data = {\n",
    "    'Sample': [],\n",
    "    'Area': [],\n",
    "    'Major Axis Length': [], #lenght of the major axis of the ellipse that has the same normalized second central moments as the region\n",
    "    'Minor Axis Length': [], # length of the minor axis of the ellipse that has the same normalized second central moments as the region\n",
    "    'Aspect Ratio': [], # ratio of the major axis length to the minor axis length\n",
    "    'Eccentricity': [], # eccentricity of the ellipse that has the same second moments as the region\n",
    "    'Solidity': [], # solidity of the region, i.e. area of the region / area of the convex hull of the region\n",
    "    'Metadata': [], # Metadata extracted from the filename\n",
    "}\n",
    "\n",
    "for sample, files in masked_filtered_images.items():\n",
    "    for filename, labeled_image, num_features, calibration in files:\n",
    "        # Extract metadata from the filename \n",
    "        match = re.search(r'_cell(\\d+)\\.nd2$', filename)\n",
    "        metadata = int(match.group(1)) if match else \"Unknown\"\n",
    "\n",
    "       # Calculate region properties\n",
    "        regions = measure.regionprops(labeled_image)\n",
    "        for region in regions:\n",
    "            data['Sample'].append(sample)\n",
    "            # Convert area and major axis length to micrometers using calibration\n",
    "            data['Area'].append(region.area * (calibration ** 2))\n",
    "            data['Major Axis Length'].append(region.major_axis_length * calibration)\n",
    "            data['Minor Axis Length'].append(region.minor_axis_length * calibration)\n",
    "            data['Aspect Ratio'].append(region.major_axis_length / region.minor_axis_length)\n",
    "            data['Eccentricity'].append(region.eccentricity)\n",
    "            data['Solidity'].append(region.solidity)\n",
    "            data['Metadata'].append(metadata)\n",
    "\n",
    "# Create a DataFrame from the data dictionary\n",
    "df_plot = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "# Plot for Area\n",
    "plt.figure(figsize=(6, 8))\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.boxplot(x = 'Sample', hue='Sample', y='Area', data=df_plot, palette='crest', showfliers=False, legend = False,\n",
    "            showmeans=True, meanprops={\"marker\":\"x\", \"markeredgecolor\":\"black\", \"markersize\":\"7\"}, linewidth=2)\n",
    "sns.stripplot(x='Sample', y='Area', data=df_plot, color='red', alpha=0.5, jitter=True, dodge=True)\n",
    "\n",
    "# # Add metadata annotations next to each data point\n",
    "# for i, row in df_plot.iterrows():\n",
    "#     plt.text(\n",
    "#         x=row['Sample'], y=row['Area'], s=str(row['Metadata']),\n",
    "#         color='blue', fontsize=8, ha='left', va='center'\n",
    "#     )\n",
    "# # Add a custom legend\n",
    "# from matplotlib.lines import Line2D\n",
    "# legend_elements = [\n",
    "#     Line2D([0], [0], marker='o', color='w', label='Datapoint', markerfacecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], marker='x', color='w', label='Mean', markeredgecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], color='blue', label='Cell numbers', markersize=0)\n",
    "# ]\n",
    "# plt.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "plt.title('Cell Area', fontsize=16, weight='bold')\n",
    "plt.ylabel(r'Area [$\\mu m^2$]', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# plt.xlabel('Sample', fontsize=12)\n",
    "# plt.tight_layout()\n",
    "plt.savefig(folder_path + 'cell_area_boxplot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot for Major Axis Length\n",
    "plt.figure(figsize=(6, 8))\n",
    "sns.boxplot(x = 'Sample', hue='Sample', y='Major Axis Length', data=df_plot, palette='crest', showfliers=False, legend=False,\n",
    "            showmeans=True, meanprops={\"marker\":\"x\", \"markeredgecolor\":\"black\", \"markersize\":\"7\"})\n",
    "sns.stripplot(x='Sample', y='Major Axis Length', data=df_plot, color='black', alpha=0.6, jitter=True, dodge=True)\n",
    "# # Add metadata annotations next to each data point\n",
    "# for i, row in df_plot.iterrows():\n",
    "#     plt.text(\n",
    "#         x=row['Sample'], y=row['Major Axis Length'], s=str(row['Metadata']),\n",
    "#         color='blue', fontsize=8, ha='left', va='center'\n",
    "#     )\n",
    "# # Add a custom legend\n",
    "# legend_elements = [\n",
    "#     Line2D([0], [0], marker='o', color='w', label='Datapoint', markerfacecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], marker='x', color='w', label='Mean', markeredgecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], color='blue', label='Cell numbers', markersize=0)\n",
    "# ]\n",
    "# plt.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "plt.title('Major Axis Length', fontsize=16, weight='bold')\n",
    "plt.ylabel(r'Major Axis Length [$\\mu $m]', fontsize=12)\n",
    "plt.xlabel('Sample', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot for Minor Axis Length\n",
    "plt.figure(figsize=(6, 8))\n",
    "sns.boxplot(x = 'Sample', hue='Sample', y='Minor Axis Length', data=df_plot, palette='crest', showfliers=False, legend=False,\n",
    "            showmeans=True, meanprops={\"marker\":\"x\", \"markeredgecolor\":\"black\", \"markersize\":\"7\"})\n",
    "sns.stripplot(x='Sample', y='Minor Axis Length', data=df_plot, color='black', alpha=0.6, jitter=True, dodge=True)\n",
    "# # Add metadata annotations next to each data point\n",
    "# for i, row in df_plot.iterrows():\n",
    "#     plt.text(\n",
    "#         x=row['Sample'], y=row['Minor Axis Length'], s=str(row['Metadata']),\n",
    "#         color='blue', fontsize=8, ha='left', va='center'\n",
    "#     )\n",
    "# # Add a custom legend\n",
    "# legend_elements = [\n",
    "#     Line2D([0], [0], marker='o', color='w', label='Datapoint', markerfacecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], marker='x', color='w', label='Mean', markeredgecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], color='blue', label='Cell numbers', markersize=0)\n",
    "# ]\n",
    "# plt.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "plt.title('Minor Axis Length', fontsize=16, weight='bold')\n",
    "plt.ylabel(r'Minor Axis Length [$\\mu $m]', fontsize=12)\n",
    "plt.xlabel('Sample', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot for Aspect Ratio\n",
    "plt.figure(figsize=(6, 8))\n",
    "sns.boxplot(x = 'Sample', hue='Sample', y='Aspect Ratio', data=df_plot, palette='crest', showfliers=False, legend=False,\n",
    "            showmeans=True, meanprops={\"marker\":\"x\", \"markeredgecolor\":\"black\", \"markersize\":\"7\"})\n",
    "sns.stripplot(x='Sample', y='Aspect Ratio', data=df_plot, color='black', alpha=0.6, jitter=True, dodge=True)\n",
    "# # Add metadata annotations next to each data point\n",
    "# for i, row in df_plot.iterrows():\n",
    "#     plt.text(\n",
    "#         x=row['Sample'], y=row['Aspect Ratio'], s=str(row['Metadata']),\n",
    "#         color='blue', fontsize=8, ha='left', va='center'\n",
    "#     )\n",
    "# # Add a custom legend\n",
    "# legend_elements = [\n",
    "#     Line2D([0], [0], marker='o', color='w', label='Datapoint', markerfacecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], marker='x', color='w', label='Mean', markeredgecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], color='blue', label='Cell numbers', markersize=0)\n",
    "# ]\n",
    "# plt.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "plt.title('Aspect Ratio', fontsize=16, weight='bold')\n",
    "plt.ylabel('Aspect Ratio', fontsize=12)\n",
    "plt.xlabel('Sample', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot for Eccentricity\n",
    "plt.figure(figsize=(6, 8))\n",
    "sns.boxplot(x = 'Sample', hue='Sample', y='Eccentricity', data=df_plot, palette='crest', showfliers=False, legend=False,\n",
    "            showmeans=True, meanprops={\"marker\":\"x\", \"markeredgecolor\":\"black\", \"markersize\":\"7\"})\n",
    "sns.stripplot(x='Sample', y='Eccentricity', data=df_plot, color='black', alpha=0.6, jitter=True, dodge=True)\n",
    "# # Add metadata annotations next to each data point\n",
    "# for i, row in df_plot.iterrows():\n",
    "#     plt.text(\n",
    "#         x=row['Sample'], y=row['Eccentricity'], s=str(row['Metadata']),\n",
    "#         color='blue', fontsize=8, ha='left', va='center'\n",
    "#     )\n",
    "# # Add a custom legend\n",
    "# legend_elements = [\n",
    "#     Line2D([0], [0], marker='o', color='w', label='Datapoint', markerfacecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], marker='x', color='w', label='Mean', markeredgecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], color='blue', label='Cell numbers', markersize=0)\n",
    "# ]\n",
    "# plt.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "plt.title('Eccentricity', fontsize=16, weight='bold')\n",
    "plt.ylabel('Eccentricity', fontsize=12)\n",
    "plt.xlabel('Sample', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot for Solidity\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x = 'Sample', hue='Sample', y='Solidity', data=df_plot, palette='crest', showfliers=False, legend=False,\n",
    "            showmeans=True, meanprops={\"marker\":\"x\", \"markeredgecolor\":\"black\", \"markersize\":\"7\"})\n",
    "sns.stripplot(x='Sample', y='Solidity', data=df_plot, color='black', alpha=0.6, jitter=True, dodge=True)\n",
    "# # Add metadata annotations next to each data point\n",
    "# for i, row in df_plot.iterrows():\n",
    "#     plt.text(\n",
    "#         x=row['Sample'], y=row['Solidity'], s=str(row['Metadata']),\n",
    "#         color='blue', fontsize=8, ha='left', va='center'\n",
    "#     )\n",
    "# # Add a custom legend\n",
    "# legend_elements = [\n",
    "#     Line2D([0], [0], marker='o', color='w', label='Datapoint', markerfacecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], marker='x', color='w', label='Mean', markeredgecolor='black', markersize=8),\n",
    "#     Line2D([0], [0], color='blue', label='Cell numbers', markersize=0)\n",
    "# ]\n",
    "# plt.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "plt.title('Solidity', fontsize=16, weight='bold')\n",
    "plt.ylabel('Solidity', fontsize=12)\n",
    "plt.xlabel('Sample', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area:\n",
      "  Mean: 3616.437\n",
      "  Std: 547.488\n",
      "  SEM: 61.597\n",
      "Major Axis Length:\n",
      "  Mean: 114.300\n",
      "  Std: 9.620\n",
      "  SEM: 1.082\n",
      "Minor Axis Length:\n",
      "  Mean: 40.342\n",
      "  Std: 3.540\n",
      "  SEM: 0.398\n",
      "Aspect Ratio:\n",
      "  Mean: 2.845\n",
      "  Std: 0.247\n",
      "  SEM: 0.028\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean and SEM of each parameter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = r'W:\\Users\\Daphne\\WT_RESULTS\\WT_IF\\region_properties_IF_allcombined.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Specify columns of interest\n",
    "columns = ['Area', 'Major Axis Length', 'Minor Axis Length', 'Aspect Ratio']\n",
    "\n",
    "# Calculate statistics\n",
    "results = {}\n",
    "for col in columns:\n",
    "    mean = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    sem = df[col].sem()\n",
    "    results[col] = {\n",
    "        'mean': mean,\n",
    "        'std': std,\n",
    "        'sem': sem\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "for col, stats in results.items():\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Mean: {stats['mean']:.3f}\")\n",
    "    print(f\"  Std: {stats['std']:.3f}\")\n",
    "    print(f\"  SEM: {stats['sem']:.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
