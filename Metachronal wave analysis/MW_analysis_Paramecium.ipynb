{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5d4afb7",
   "metadata": {},
   "source": [
    "# Metachronal wave analysis for Paramecium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925773de",
   "metadata": {},
   "source": [
    "This script quantifies metachronal wave (MW) properties in Paramecium cells from timelapse microscopy data. It assumes that input timelapses are pre-registered (e.g., using StackReg in ImageJ). Before running this script, the user must manually select a straight line along the direction of metachronal wave propagation in ImageJ and save the coordinates as a .csv file. The script preprocesses the image stack (illumination correction, normalization), then generates a kymograph by averaging intensities along a sliding box perpendicular to the selected segment. The kymograph represents spatial and temporal changes in ciliary activity. The script computes the 2D autocorrelation of the kymograph using the Wiener-Khinchin theorem (via Fourier transforms), and extracts MW parameters: ciliary beat frequency (CBF), wavelength, and wave velocity, with error estimates. The analysis includes steps to optimize the selection of the MW direction by generating rotated lines around the initial selection and identifying the angle that minimizes the wavelength. The output includes visualizations (kymograph, autocorrelation, power spectral densities) and a summary of MW parameters with errors saved in CSV format.\n",
    "\n",
    "*Note*: This code loads functions from functions.py.\n",
    "\n",
    "The code is adjusted from the metachronal wave analysis performed by Katerina Kourkoulou: https://github.com/livingpatterns/MW_dynamics_Didinium\n",
    "The code follows the approach of: https://github.com/shurlimann/stentor-cilia-autocorrelation?tab=readme-ov-file where a segment of the MW is selected manualy, parametrized and by sliding a box within which the signal is averaged a kymograph is calculated.\n",
    "\n",
    "\n",
    "Input:\n",
    "- Paths\n",
    "*file_directory* : The path to the directory containing the tif file to be analyzed. An output folder will be created in the same location.\n",
    "*file_name*      : The name of the tif file of the registered Paramecium.\n",
    "\n",
    "- Parameters from raw data:\n",
    "*pixel_size*                  : The pixel size that can be found from the raw file.\n",
    "*fps*                         : The frame rate that can be found from the raw file.\n",
    "\n",
    "- Spline parameters:\n",
    "*new_spatial_resolution*      : After the manual selection of the segment of the MW to be analyzed a homogeneous distribution of points is generated with a spline. Its target resolution is set in microns with this parameter. Values should be larger than the pixel_size to avoid oversampling. **Note:** There is currently a problem with the rescaling!\n",
    "*s*                           : Controls trade-off of line smoothness and close fit.\n",
    "*k*                           : The degree of the spline. Should be odd number. (Recommendation is 3)\n",
    "\n",
    "- Parameters for assistive box mask:\n",
    "After the spline is calculated a box mask of desired size is generated and then slided along the spline in a perpendicular manner. Intensities inside the box are averaged to create an 1D representation of the segment and generate the kymograph.\n",
    "*box_width*    :   The desired box width in pixels\n",
    "*box_length*   :   The desired box length in pixels\n",
    "\n",
    "\n",
    "Output:\n",
    "- The code saves automatically for visual inspection: the first frame before and after normalization, the selected points of the manual ROI selection, the kymograph and the autocorrelation, the PSD for the frequency (CBF) and the wavelength and four plots for evaluating the quality of the velocity detection.\n",
    "- Additionally, there are two csv files:\n",
    "*output_results*:  Collects or image info, a given cell_id, main metadata and all output values with the corresponding errors. In case file names and organization does not match the expected format you might need to manually give that information at the very end of the code following the comments there.\n",
    "*parameters.csv*:  The parameters chosen to run the code. \n",
    "\n",
    "Important note: Files are overwritten in every run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate, signal\n",
    "from scipy.fft import fft2, fftshift, ifft2, ifftshift, fft, ifft, fftfreq\n",
    "from scipy.optimize import leastsq\n",
    "from skimage import filters, measure\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.draw import disk\n",
    "from skimage.morphology import disk as disk_vel\n",
    "import numpy.matlib as matlib\n",
    "import scipy.ndimage as ndimage\n",
    "import polarTransform\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "from functions import *\n",
    "import matplotlib as mpl\n",
    "# Ensure text is saved as editable text in SVG\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "# Set global font to Arial\n",
    "mpl.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11259a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INPUT ---------------------------------------------------------------------\n",
    "# Path to folder of registered MW time-lapse and name of the tiff file to be processed\n",
    "file_directory = \"W:/Users/Daphne/RESULTS/Dynamics/Live imaging p.tet WT surface cell/\"\n",
    "file_name = \"ptetwt_40x_03.tif\"\n",
    "\n",
    "## Parameters\n",
    "# from tiff file:\n",
    "pixel_size = 0.23  # μm     Fast camera 40x\n",
    "fps = 1000\n",
    "pixel_size2 = pixel_size\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Following parameters not needed when taking a straight line!\n",
    "# Spline parameters:\n",
    "# After manual selection of a segment of the MW, the points are re-parametrized to achieve a desired resolution using a spline\n",
    "new_spatial_resolution = pixel_size\n",
    "s=5 # smoothing condition (controls the trade-off between closeness and smoothness of fit)\n",
    "k=3 # degree of the spline (avoid even numbers, recommended is k=3)\n",
    "# Parameters for assistive box mask:\n",
    "# To prepare for the kymograph a box mask slides over the spline within which intensities are averages.\n",
    "box_width   = 1     # (pixels) width of box used to average out the intensities   (needs to be optimized)\n",
    "box_length  = 5      # (pixels) length of box used to average out the intensities  (needs to be optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bfe762",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-PROCESSING ------------------------------------------------------------\n",
    "# Sets file path and makes output folder\n",
    "file_path = file_directory + \"\\\\\" + file_name\n",
    "special_folder = \"test_before_push\\\\\"\n",
    "output_path = file_directory + \"\\\\output_MW\\\\\" + special_folder\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "# Reading file info\n",
    "image, frame_width, frame_height, num_frames = open_tif(file_path)\n",
    "\n",
    "#----- to test the file was loaded properly: -------\n",
    "print(\"Number of frames :\", num_frames)\n",
    "print(\"Frame width:\", frame_width)\n",
    "print(\"Frame height:\", frame_height)\n",
    "\n",
    "frame_index = 0\n",
    "show_frame_no_axes(image,frame_index)\n",
    "plt.savefig(output_path + \"first_frame.png\", dpi=300)\n",
    "#---------------------------------------------------\n",
    "\n",
    "### Signal normalization\n",
    "image_illum_fix = uneven_illumination_fix(image, 31)\n",
    "image_norm = img_norm_simple(image_illum_fix)\n",
    "\n",
    "### Optional: save the normalized video\n",
    "tifffile.imwrite(file_path + file_name[:-4] + 'image_fix_norm.tif', image_norm)\n",
    "\n",
    "#------- to display: ------------------------------\n",
    "frame_index = 0\n",
    "show_frame_no_axes(image_norm,frame_index)\n",
    "plt.savefig(output_path + \"first_frame_normalized.png\", dpi=300)\n",
    "plt.show()\n",
    "#---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### For Paramecium: Prepare in ImageJ the points of the ciliary array to be analyzed. Plot a straight line along the cilia and save the coordinates in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use the following code to read the predefined points:\n",
    "cilia_path = file_directory + \"\\\\ptetwt_40x_03_doublets.csv\"  # path to the csv file with the selected points\n",
    "\n",
    "with open(cilia_path, 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    points_manual = np.array([[int(row[0]), int(row[1])] for row in reader])\n",
    "\n",
    "x_manual = points_manual[:, 0]\n",
    "y_manual = points_manual[:, 1]\n",
    "#----- to check the file was read properly -------\n",
    "plt.figure()\n",
    "plt.imshow(image[0,:,:], cmap='binary')\n",
    "plt.scatter(x_manual,y_manual, color ='r', s = 5)\n",
    "plt.show()\n",
    "#-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Make sure the line is straight (take the first and last points of the line) and calculate the angle of the line compared to the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to calculate the angle of a line compared to the y-axis\n",
    "def calculate_angle(x_start, y_start, x_end, y_end):\n",
    "    delta_x = x_end - x_start\n",
    "    delta_y = y_end - y_start\n",
    "    angle = np.degrees(np.arctan2(delta_x, delta_y))  # Angle in degrees\n",
    "    return angle\n",
    "\n",
    "# Define the original line using the first and last points of the manually drawn line\n",
    "x_start, y_start = points_manual[0]\n",
    "x_end, y_end = points_manual[-1]\n",
    "\n",
    "# Create the original line as a NumPy array\n",
    "original_line = np.array([[x_start, y_start], [x_end, y_end]])\n",
    "\n",
    "# Calculate the center of the line\n",
    "x_center = (x_start + x_end) / 2\n",
    "y_center = (y_start + y_end) / 2\n",
    "\n",
    "# Calculate the angle compared to the y-axis\n",
    "angle = calculate_angle(x_start, y_start, x_end, y_end)\n",
    "\n",
    "# Plot the original line\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image[0], cmap='gray')\n",
    "plt.plot([x_start, x_end], [y_start, y_end], 'r-', label=f'Original Line (Angle: {angle:.2f}°)')\n",
    "plt.scatter(x_center, y_center, color='blue', label='Center')\n",
    "plt.legend()\n",
    "plt.title('Original Line')\n",
    "plt.savefig(output_path + \"input_line.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Angle of the original line compared to the y-axis: {angle:.2f}°\")\n",
    "# print length of the line\n",
    "length = np.sqrt((x_end - x_start)**2 + (y_end - y_start)**2)\n",
    "print(f\"Length of the original line: {length:.2f} pixels = {length * pixel_size:.2f} microns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the kymograph for the original\n",
    "# straight line\n",
    "# Step 1: Define a curve/spline along the selection and generate 1D representation of the ciliary array\n",
    "# Ensure the number of points is sufficient for the spline degree\n",
    "if len(x_manual) <= k:\n",
    "    k = len(x_manual) - 1  # Reduce k to be less than the number of points\n",
    "\n",
    "x_cilia, y_cilia = spline_generator(x_manual, y_manual, pixel_size2, new_spatial_resolution, s, k)\n",
    "x_int, y_int, x_residue, y_residue, dx, dy = x_y_to_indices(x_cilia, y_cilia)\n",
    "theta = np.arctan(dx / dy) * 180 / np.pi\n",
    "box, center = assistive_box_mask(box_width, box_length)\n",
    "c_intensity = apply_box_mask(image_norm, box, theta, center, box_width, box_length, x_residue, y_residue, x_int, y_int, num_frames)\n",
    "c_intensity = c_intensity.iloc[:, 10:]  # OPTIONAL: to crop the first few pixels that are noisy\n",
    "\n",
    "# Step 2: Normalize the kymograph\n",
    "c_intensity_min = np.min(c_intensity)\n",
    "c_intensity_max = np.max(c_intensity)\n",
    "c_intensity_norm = (c_intensity - c_intensity_min) / (c_intensity_max - c_intensity_min)\n",
    "\n",
    "# Step 3: Display the kymograph\n",
    "aspect_ratio = 100  # Adjust as needed\n",
    "# num_frames = c_intensity.index.max() + 1 # to plot the kymograph rescaled in sec\n",
    "# num_pixels = c_intensity.columns.max() + 1 # to plot the kymograph rescaled in μm\n",
    "num_frames = c_intensity.shape[0]  # Number of frames\n",
    "num_pixels = c_intensity.shape[1]  # Number of pixels\n",
    "new_index = pd.Index(np.arange(num_frames) / fps)\n",
    "new_columns = pd.Index(np.arange(num_pixels) * new_spatial_resolution)\n",
    "\n",
    "# Reindex the DataFrame\n",
    "rescaled_c_intensity = c_intensity.copy()\n",
    "rescaled_c_intensity.index = new_index\n",
    "rescaled_c_intensity.columns = new_columns\n",
    "rescaled_c_intensity.index.name = 'time (sec)'\n",
    "rescaled_c_intensity.columns.name = 'position along the cilia (\\u03BCm)'\n",
    "\n",
    "# kymograph_display_units(rescaled_c_intensity.iloc[:], aspect_ratio)\n",
    "kymograph_display_units(rescaled_c_intensity.iloc[:])\n",
    "plt.savefig(output_path + \"kymograph_original_line.png\", dpi=300)\n",
    "plt.savefig(output_path + \"kymograph_original_line.svg\", format='svg')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Calculate and display the autocorrelation\n",
    "c = autocorrelation2D_fft_units(c_intensity_norm)\n",
    "index_t = np.arange(c.shape[0]) / fps\n",
    "index_x = np.arange(c.shape[1]) * new_spatial_resolution\n",
    "correlation = pd.DataFrame(c, index=pd.Index(index_t, name='dt (sec)'), columns=pd.Index(index_x, name='dx (μm)'))\n",
    "\n",
    "# visualization\n",
    "autocorrelation2D_visualization_units(correlation.iloc[:])\n",
    "# autocorrelation2D_visualization_units(correlation.iloc[:], aspect_ratio)\n",
    "plt.savefig(output_path + \"autocorrelation_original_line.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If the kymograph has a lot of background it confuses the autocorrelation.\n",
    "# This can partially be avoided with a median filter:\n",
    "aspect_ratio = 100  # Adjust as needed\n",
    "# Load the kymograph image (replace this with your image)\n",
    "kymograph = rescaled_c_intensity\n",
    "filter_size = 50\n",
    "\n",
    "# Apply a median filter along the x-axis to suppress vertical lines\n",
    "filtered_kymograph = median_filter(kymograph, size=(filter_size, 1))  # size=(1, width of filter)\n",
    "corrected_kymograph = kymograph - filtered_kymograph\n",
    "\n",
    "# Plot original and filtered kymographs side by side\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original kymograph\n",
    "ax1.imshow(kymograph, cmap='grey', aspect='auto')\n",
    "ax1.set_title('Original Kymograph')\n",
    "# Filtered kymograph\n",
    "ax2.imshow(filtered_kymograph, cmap='grey', aspect='auto')\n",
    "ax2.set_title('Filtered Kymograph (median, (' + str(filter_size) + ',1))')\n",
    "# Corrected kymograph\n",
    "ax3.imshow(corrected_kymograph, cmap='grey', aspect='auto')\n",
    "ax3.set_title('Corrected Kymograph')\n",
    "plt.savefig(output_path + \"filtered_kymograph_original_line.png\")\n",
    "\n",
    "# Using the line below you can look closer to a certain segment of the kymograph e.g. first 100 frames:\n",
    "# kymograph_display_units(corrected_kymograph.iloc[:,:], aspect_ratio)\n",
    "def kymograph_display_units(c_intensity):\n",
    "    \"\"\"\n",
    "    Plots a given kymograph with rescaled axes in μm and sec.\n",
    "    c_intensity should be rescaled beforehand.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(c_intensity, aspect = 40, origin = 'lower', extent=[c_intensity.columns[0], c_intensity.columns[-1], c_intensity.index[0], c_intensity.index[-1]], cmap = mpl.colormaps.get_cmap('gray'))\n",
    "    plt.title('Kymograph of image intensity', fontsize = 13)\n",
    "    plt.grid(False)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel('dx (\\u03BCm)', fontsize = 10)\n",
    "    plt.ylabel('dt (sec)', fontsize = 10)\n",
    "\n",
    "    return\n",
    "\n",
    "kymograph_display_units(corrected_kymograph.iloc[250:1250,:])\n",
    "plt.savefig(output_path + \"kymograph_corrected_original_line_zoom.png\", dpi=300)\n",
    "plt.savefig(output_path + \"kymograph_corrected_original_line_zoom.svg\", format='svg')\n",
    "# kymograph_display_units(corrected_kymograph, aspect_ratio)\n",
    "# Save corrected kymograph:\n",
    "corrected_kymograph.to_pickle(output_path + \"corrected_kymograph_original_line.pkl\")\n",
    "plt.savefig(output_path + \"kymograph_corrected_original_line.png\", dpi=300)\n",
    "plt.savefig(output_path + \"kymograph_corrected_original_line.svg\", format='svg')\n",
    "plt.show()\n",
    "\n",
    "# plot autocorrelation of the corrected kymograph\n",
    "c = autocorrelation2D_fft_units(corrected_kymograph)\n",
    "index_t = np.arange(c.shape[0]) / fps\n",
    "index_x = np.arange(c.shape[1]) * new_spatial_resolution\n",
    "correlation = pd.DataFrame(c, index=pd.Index(index_t, name='dt (sec)'), columns=pd.Index(index_x, name='dx (μm)'))\n",
    "\n",
    "def autocorrelation2D_visualization_units(c):\n",
    "    \"\"\"\n",
    "    Displays the autocorrelation in space (μm) and time (sec).\n",
    "    Aspect ratio is adjusted considering that usual fps is in the magnitude of 1000.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(c, aspect = 60/1, origin = 'lower', extent=[c.columns[0], c.columns[-1], c.index[0], c.index[-1]], cmap = mpl.colormaps.get_cmap('jet'))\n",
    "    plt.colorbar(label='Autocorrelation Intensity')\n",
    "\n",
    "    plt.title('2D Autocorrelation', fontsize = 13)\n",
    "    plt.grid(False)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel('dx (\\u03BCm)', fontsize = 10)\n",
    "    plt.ylabel('dt (sec)', fontsize = 10)\n",
    "\n",
    "    return\n",
    "\n",
    "# autocorrelation2D_visualization_units(correlation.iloc[:], aspect_ratio)\n",
    "autocorrelation2D_visualization_units(correlation.iloc[:200])\n",
    "plt.savefig(output_path + \"autocorrelation_corrected_kymograph.png\", dpi=300)\n",
    "plt.savefig(output_path + \"autocorrelation_corrected_kymograph.svg\", format='svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print min and max value of c\n",
    "print(f\"Min value of autocorrelation: {np.min(c)}\")\n",
    "print(f\"Max value of autocorrelation: {np.max(c)}\")\n",
    "\n",
    "# plot c histogram of values\n",
    "plt.figure()\n",
    "plt.hist(c.flatten(), bins=100, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of Autocorrelation Values')\n",
    "plt.xlabel('Autocorrelation Value')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "# plt.savefig(output_path + \"autocorrelation_histogram.png\", dpi=300)\n",
    "# plt.savefig(output_path + \"autocorrelation_histogram.svg\", format='svg')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output_CBF_average(correlation, temporal_sampling_freq):\n",
    "    \"\"\"\n",
    "    Calculation of the CBF using the autocorrelation pattern by averaging over all lags in space.\n",
    "    Errors are estimated by the full width at half maximum (FWHM).\n",
    "    \"\"\"\n",
    "\n",
    "    num_frames = correlation.shape[0]\n",
    "    num_dx = correlation.shape[1]\n",
    "\n",
    "    # For space_lag = 0\n",
    "    space_lag = 0\n",
    "    frequencies_0, psd_t_0 = signal.welch(correlation.iloc[:, space_lag], fs=temporal_sampling_freq, nperseg=num_frames)\n",
    "\n",
    "    size_psd = psd_t_0.shape[0]\n",
    "\n",
    "    # For all space lags\n",
    "    frequencies_all = np.zeros((num_dx, size_psd))\n",
    "    psd_t_all = np.zeros((num_dx, size_psd))\n",
    "\n",
    "    frequencies_all[0,:] = frequencies_0\n",
    "    psd_t_all[0,:] = psd_t_0\n",
    "\n",
    "    # Loop over space_lag values from 1 to num_dx - 1\n",
    "    for space_lag in range(1, num_dx):\n",
    "        # Calculate power spectral density using Welch's method\n",
    "        frequencies, psd_t = signal.welch(correlation.iloc[:, space_lag], fs=temporal_sampling_freq, nperseg=num_frames)\n",
    "\n",
    "\n",
    "        # Store the results\n",
    "        frequencies_all[space_lag, :] = frequencies\n",
    "        psd_t_all[space_lag, :] = psd_t\n",
    "\n",
    "    # Average along the rows\n",
    "    average_frequencies = np.mean(frequencies_all, axis=0)\n",
    "    average_psd_t = np.mean(psd_t_all, axis=0)\n",
    "\n",
    "    # std along the rows\n",
    "    std_frequencies = np.std(frequencies_all, axis=0)\n",
    "    std_psd_t = np.std(psd_t_all, axis=0)\n",
    "\n",
    "    # normalization:\n",
    "    average_psd_t = average_psd_t / np.max(average_psd_t)\n",
    "    std_psd_t     = std_psd_t / np.max(average_psd_t)\n",
    "\n",
    "    # Find the peaks in the psd:\n",
    "    peaks, _ = signal.find_peaks(average_psd_t)\n",
    "\n",
    "    # identify the primary frequency that should correspond to the CBF:\n",
    "    sorted_peaks = peaks[np.argsort(average_psd_t[peaks])][::-1]\n",
    "    primary_peak = sorted_peaks[0] if sorted_peaks[0] < 5 else sorted_peaks[0]\n",
    "    CBF = average_frequencies[primary_peak]\n",
    "\n",
    "\n",
    "    # Calculate FWHM\n",
    "    half_max = average_psd_t[primary_peak] / 2\n",
    "    left_idx = np.where(average_psd_t[:primary_peak] <= half_max)[0]\n",
    "    right_idx = np.where(average_psd_t[primary_peak:] <= half_max)[0]\n",
    "\n",
    "    if len(left_idx) > 0 and len(right_idx) > 0:\n",
    "        left_half_max = average_frequencies[left_idx[-1]]\n",
    "        right_half_max = average_frequencies[primary_peak + right_idx[0]]\n",
    "        fwhm = right_half_max - left_half_max\n",
    "        CBF_error = fwhm / 2  # Using half of FWHM as the error estimate\n",
    "    else:\n",
    "        CBF_error = 0  # Default to 0 if FWHM cannot be determined\n",
    "\n",
    "    return average_frequencies, average_psd_t,std_frequencies, std_psd_t, CBF, CBF_error\n",
    "\n",
    "\n",
    "def output_wavelength_average(correlation, spatial_sampling_freq):\n",
    "    \"\"\"\n",
    "    Calculation of the wavelength using the autocorrelation pattern by averaging over all lags in time.\n",
    "    Errors are estimated by the full width at half maximum (FWHM).\n",
    "    \"\"\"\n",
    "\n",
    "    N = correlation.shape[1]\n",
    "    num_dt = correlation.shape[0]\n",
    "\n",
    "    # For time_lag = 0\n",
    "    time_lag = 0\n",
    "    wavenumbers_0, psd_x_0 = signal.welch(correlation.iloc[time_lag, :], fs=spatial_sampling_freq, nperseg=N)\n",
    "\n",
    "    size_psd = psd_x_0.shape[0]\n",
    "\n",
    "    wavenumbers_all = np.zeros((num_dt, size_psd))\n",
    "    psd_x_all = np.zeros((num_dt, size_psd))\n",
    "\n",
    "    wavenumbers_all[0,:] = wavenumbers_0\n",
    "    psd_x_all[0,:] = psd_x_0\n",
    "\n",
    "    for time_lag in range(1, num_dt):\n",
    "        # Calculate power spectral density using Welch's method\n",
    "        wavenumbers, psd_x = signal.welch(correlation.iloc[time_lag, :], fs=spatial_sampling_freq, nperseg=N)\n",
    "\n",
    "        # Store the results\n",
    "        wavenumbers_all[time_lag, :] = wavenumbers\n",
    "        psd_x_all[time_lag, :] = psd_x\n",
    "\n",
    "    # Average along the rows\n",
    "    average_wavenumbers = np.mean(wavenumbers_all, axis=0)\n",
    "    average_psd_x = np.mean(psd_x_all, axis=0)\n",
    "\n",
    "    # std along the rows\n",
    "    std_wavenumbers = np.std(wavenumbers_all, axis=0)\n",
    "    std_psd_x = np.std(psd_x_all, axis=0)\n",
    "\n",
    "    # normalization:\n",
    "    average_psd_x = average_psd_x / np.mean(average_psd_x)\n",
    "    std_psd_x     = std_psd_x /  np.mean(average_psd_x)\n",
    "\n",
    "    peaks, _ = signal.find_peaks(average_psd_x)\n",
    "    sorted_peaks = peaks[np.argsort(average_psd_x[peaks])][::-1]\n",
    "    primary_peak = sorted_peaks[1] if sorted_peaks[0] <= 0 else sorted_peaks[0]\n",
    "    primary_wavenumber = average_wavenumbers[primary_peak]\n",
    "\n",
    "    # Calculate FWHM\n",
    "    half_max = average_psd_x[primary_peak] / 2\n",
    "    left_idx = np.where(average_psd_x[:primary_peak] <= half_max)[0]\n",
    "    right_idx = np.where(average_psd_x[primary_peak:] <= half_max)[0]\n",
    "\n",
    "    if len(left_idx) > 0 and len(right_idx) > 0:\n",
    "        left_half_max = average_wavenumbers[left_idx[-1]]\n",
    "        right_half_max = average_wavenumbers[primary_peak + right_idx[0]]\n",
    "        fwhm = right_half_max - left_half_max\n",
    "        wavenumber_error = fwhm / 2  # Using half of FWHM as the error estimate\n",
    "    else:\n",
    "        wavenumber_error = 0  # Default to 0 if FWHM cannot be determined\n",
    "\n",
    "    wavelength = 1 / primary_wavenumber\n",
    "    wavelength_error = (1 / primary_wavenumber)**2 * wavenumber_error\n",
    "\n",
    "    return average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, wavelength, wavelength_error, primary_wavenumber, wavenumber_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CBF by averaging over all space lags:\n",
    "temporal_sampling_freq = fps\n",
    "frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error = output_CBF_average(correlation, temporal_sampling_freq)\n",
    "# Plotting of PSD with CBF:\n",
    "plot_CBF(frequencies, psd_t_norm, std_psd_t, CBF, CBF_error)\n",
    "plt.savefig(output_path + \"PSD_CBF.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# λ by averaging over all space lags:\n",
    "spatial_sampling_freq = 1/pixel_size  # pixel/μm\n",
    "# spatial_sampling_freq = 1 # because data is already in μm (?)\n",
    "average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, wavelength, wavelength_error, primary_wavenumber, wavenumber_error = output_wavelength_average(correlation.iloc[:,:], spatial_sampling_freq)\n",
    "# Plotting of PSD with λ:\n",
    "plot_wavelength(average_wavenumbers, average_psd_x, std_psd_x, primary_wavenumber, wavenumber_error,wavelength, wavelength_error)\n",
    "plt.savefig(output_path + \"PSD_wavelength.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generate rotated lines for testing\n",
    "We can generate rotated lines around the center of the original line. We use this to find the actual MW direction. The angle that corresponds to the lowest wavelength is the actual MW direction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to generate rotated lines\n",
    "def generate_rotated_lines(x_start, y_start, x_end, y_end, x_center, y_center, angles):\n",
    "    rotated_lines = []\n",
    "    for angle in angles:\n",
    "        rotation_matrix = np.array([\n",
    "            [np.cos(np.radians(angle)), -np.sin(np.radians(angle))],\n",
    "            [np.sin(np.radians(angle)), np.cos(np.radians(angle))]\n",
    "        ])\n",
    "        original_line = np.array([[x_start, y_start], [x_end, y_end]])\n",
    "        rotated_line = (original_line - [x_center, y_center]) @ rotation_matrix.T + [x_center, y_center]\n",
    "        rotated_lines.append(rotated_line)\n",
    "    return rotated_lines\n",
    "\n",
    "# Define angles for rotation\n",
    "angles = [-20, -15, -10, -5, 5, 10, 15, 20]  # Adjust as needed\n",
    "\n",
    "# Generate rotated lines\n",
    "rotated_lines = generate_rotated_lines(x_start, y_start, x_end, y_end, x_center, y_center, angles)\n",
    "\n",
    "# Plot the original and rotated lines\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image[0], cmap='gray')\n",
    "plt.plot([x_start, x_end], [y_start, y_end], 'r-', label='Original Line')\n",
    "for i, line in enumerate(rotated_lines):\n",
    "    plt.plot(line[:, 0], line[:, 1], label=f'Rotated Line {i+1} ({angles[i]}°)')\n",
    "plt.scatter(x_center, y_center, color='blue', label='Center')\n",
    "plt.legend()\n",
    "plt.title('Original and Rotated Lines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # RUN IF YOU WANT TO CHANGE THE CHOSEN PEAKS\n",
    "# def output_CBF_average(correlation, temporal_sampling_freq):\n",
    "#     \"\"\"\n",
    "#     Calculation of the CBF using the autocorrelation pattern by averaging over all lags in space.\n",
    "#     Errors are estimated by the full width at half maximum (FWHM).\n",
    "#     \"\"\"\n",
    "#\n",
    "#     num_frames = correlation.shape[0]\n",
    "#     num_dx = correlation.shape[1]\n",
    "#\n",
    "#     # For space_lag = 0\n",
    "#     space_lag = 0\n",
    "#     frequencies_0, psd_t_0 = signal.welch(correlation.iloc[:, space_lag], fs=temporal_sampling_freq, nperseg=num_frames)\n",
    "#\n",
    "#     size_psd = psd_t_0.shape[0]\n",
    "#\n",
    "#     # For all space lags\n",
    "#     frequencies_all = np.zeros((num_dx, size_psd))\n",
    "#     psd_t_all = np.zeros((num_dx, size_psd))\n",
    "#\n",
    "#     frequencies_all[0,:] = frequencies_0\n",
    "#     psd_t_all[0,:] = psd_t_0\n",
    "#\n",
    "#     # Loop over space_lag values from 1 to num_dx - 1\n",
    "#     for space_lag in range(1, num_dx):\n",
    "#         # Calculate power spectral density using Welch's method\n",
    "#         frequencies, psd_t = signal.welch(correlation.iloc[:, space_lag], fs=temporal_sampling_freq, nperseg=num_frames)\n",
    "#\n",
    "#\n",
    "#         # Store the results\n",
    "#         frequencies_all[space_lag, :] = frequencies\n",
    "#         psd_t_all[space_lag, :] = psd_t\n",
    "#\n",
    "#     # Average along the rows\n",
    "#     average_frequencies = np.mean(frequencies_all, axis=0)\n",
    "#     average_psd_t = np.mean(psd_t_all, axis=0)\n",
    "#\n",
    "#     # std along the rows\n",
    "#     std_frequencies = np.std(frequencies_all, axis=0)\n",
    "#     std_psd_t = np.std(psd_t_all, axis=0)\n",
    "#\n",
    "#     # normalization:\n",
    "#     average_psd_t = average_psd_t / np.max(average_psd_t)\n",
    "#     std_psd_t     = std_psd_t / np.max(average_psd_t)\n",
    "#\n",
    "#     # Find the peaks in the psd:\n",
    "#     peaks, _ = signal.find_peaks(average_psd_t)\n",
    "#\n",
    "#     # identify the primary frequency that should correspond to the CBF:\n",
    "#     sorted_peaks = peaks[np.argsort(average_psd_t[peaks])][::-1]\n",
    "#     primary_peak = sorted_peaks[1] if sorted_peaks[0] < 5 else sorted_peaks[0]\n",
    "#     CBF = average_frequencies[primary_peak]\n",
    "#\n",
    "#     # Calculate FWHM\n",
    "#     half_max = average_psd_t[primary_peak] / 2\n",
    "#     left_idx = np.where(average_psd_t[:primary_peak] <= half_max)[0]\n",
    "#     right_idx = np.where(average_psd_t[primary_peak:] <= half_max)[0]\n",
    "#\n",
    "#     if len(left_idx) > 0 and len(right_idx) > 0:\n",
    "#         left_half_max = average_frequencies[left_idx[-1]]\n",
    "#         right_half_max = average_frequencies[primary_peak + right_idx[0]]\n",
    "#         fwhm = right_half_max - left_half_max\n",
    "#         CBF_error = fwhm / 2  # Using half of FWHM as the error estimate\n",
    "#     else:\n",
    "#         CBF_error = 0  # Default to 0 if FWHM cannot be determined\n",
    "#\n",
    "#     return average_frequencies, average_psd_t,std_frequencies, std_psd_t, CBF, CBF_error\n",
    "#\n",
    "#\n",
    "# def output_wavelength_average(correlation, spatial_sampling_freq):\n",
    "#     \"\"\"\n",
    "#     Calculation of the wavelength using the autocorrelation pattern by averaging over all lags in time.\n",
    "#     Errors are estimated by the full width at half maximum (FWHM).\n",
    "#     \"\"\"\n",
    "#\n",
    "#     N = correlation.shape[1]\n",
    "#     num_dt = correlation.shape[0]\n",
    "#\n",
    "#     # For time_lag = 0\n",
    "#     time_lag = 0\n",
    "#     wavenumbers_0, psd_x_0 = signal.welch(correlation.iloc[time_lag, :], fs=spatial_sampling_freq, nperseg=N)\n",
    "#\n",
    "#     size_psd = psd_x_0.shape[0]\n",
    "#\n",
    "#     wavenumbers_all = np.zeros((num_dt, size_psd))\n",
    "#     psd_x_all = np.zeros((num_dt, size_psd))\n",
    "#\n",
    "#     wavenumbers_all[0,:] = wavenumbers_0\n",
    "#     psd_x_all[0,:] = psd_x_0\n",
    "#\n",
    "#     for time_lag in range(1, num_dt):\n",
    "#         # Calculate power spectral density using Welch's method\n",
    "#         wavenumbers, psd_x = signal.welch(correlation.iloc[time_lag, :], fs=spatial_sampling_freq, nperseg=N)\n",
    "#\n",
    "#         # Store the results\n",
    "#         wavenumbers_all[time_lag, :] = wavenumbers\n",
    "#         psd_x_all[time_lag, :] = psd_x\n",
    "#\n",
    "#     # Average along the rows\n",
    "#     average_wavenumbers = np.mean(wavenumbers_all, axis=0)\n",
    "#     average_psd_x = np.mean(psd_x_all, axis=0)\n",
    "#\n",
    "#     # std along the rows\n",
    "#     std_wavenumbers = np.std(wavenumbers_all, axis=0)\n",
    "#     std_psd_x = np.std(psd_x_all, axis=0)\n",
    "#\n",
    "#     # normalization:\n",
    "#     average_psd_x = average_psd_x / np.mean(average_psd_x)\n",
    "#     std_psd_x     = std_psd_x /  np.mean(average_psd_x)\n",
    "#\n",
    "#     peaks, _ = signal.find_peaks(average_psd_x)\n",
    "#     sorted_peaks = peaks[np.argsort(average_psd_x[peaks])][::-1]\n",
    "#     primary_peak = sorted_peaks[0] if sorted_peaks[0] <= 0 else sorted_peaks[0]\n",
    "#     primary_wavenumber = average_wavenumbers[primary_peak]\n",
    "#\n",
    "#     # Calculate FWHM\n",
    "#     half_max = average_psd_x[primary_peak] / 2\n",
    "#     left_idx = np.where(average_psd_x[:primary_peak] <= half_max)[0]\n",
    "#     right_idx = np.where(average_psd_x[primary_peak:] <= half_max)[0]\n",
    "#\n",
    "#     if len(left_idx) > 0 and len(right_idx) > 0:\n",
    "#         left_half_max = average_wavenumbers[left_idx[-1]]\n",
    "#         right_half_max = average_wavenumbers[primary_peak + right_idx[0]]\n",
    "#         fwhm = right_half_max - left_half_max\n",
    "#         wavenumber_error = fwhm / 2  # Using half of FWHM as the error estimate\n",
    "#     else:\n",
    "#         wavenumber_error = 0  # Default to 0 if FWHM cannot be determined\n",
    "#\n",
    "#     wavelength = 1 / primary_wavenumber\n",
    "#     wavelength_error = (1 / primary_wavenumber)**2 * wavenumber_error\n",
    "#\n",
    "#     return average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, wavelength, wavelength_error, primary_wavenumber, wavenumber_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store PSD data\n",
    "psd_cbf_data = []\n",
    "psd_wavelength_data = []\n",
    "\n",
    "# Perform the same calculations for each rotated line as was done for the original line\n",
    "# Convert input lists to NumPy arrays before calling spline_generator\n",
    "for i, line in enumerate(rotated_lines):\n",
    "    # Step 1: Define a curve/spline along the selection and generate 1D representation of the ciliary array\n",
    "    x_start_rotated, y_start_rotated = line[0]\n",
    "    x_end_rotated, y_end_rotated = line[1]\n",
    "    # Convert to NumPy arrays\n",
    "    x_manual_rotated = np.array([x_start_rotated, x_end_rotated])\n",
    "    y_manual_rotated = np.array([y_start_rotated, y_end_rotated])\n",
    "    # Ensure the number of points is sufficient for the spline degree\n",
    "    if len(x_manual_rotated) <= k:\n",
    "        k = len(x_manual_rotated) - 1  # Reduce k to be less than the number of points\n",
    "\n",
    "    # Call spline_generator with NumPy arrays\n",
    "    x_cilia_rotated, y_cilia_rotated = spline_generator(x_manual_rotated, y_manual_rotated, pixel_size, new_spatial_resolution, s, k)\n",
    "    x_int_rotated, y_int_rotated, x_residue_rotated, y_residue_rotated, dx_rotated, dy_rotated = x_y_to_indices(x_cilia_rotated, y_cilia_rotated)\n",
    "    theta_rotated = np.arctan(dx_rotated / dy_rotated) * 180 / np.pi\n",
    "    box_rotated, center_rotated = assistive_box_mask(box_width, box_length)\n",
    "    c_intensity = apply_box_mask(image_norm, box_rotated, theta_rotated, center_rotated, box_width, box_length, x_residue_rotated, y_residue_rotated, x_int_rotated, y_int_rotated, num_frames)\n",
    "\n",
    "    # Step 2: Normalize the kymograph\n",
    "    c_intensity_min = np.min(c_intensity)\n",
    "    c_intensity_max = np.max(c_intensity)\n",
    "    c_intensity_norm = (c_intensity - c_intensity_min) / (c_intensity_max - c_intensity_min)\n",
    "\n",
    "    # Step 3: Display the kymograph\n",
    "    num_frames = c_intensity.shape[0]\n",
    "    num_pixels = c_intensity.shape[1]\n",
    "    new_index = pd.Index(np.arange(num_frames) / fps)\n",
    "    new_columns = pd.Index(np.arange(num_pixels) * new_spatial_resolution)\n",
    "    rescaled_c_intensity = c_intensity.copy()\n",
    "    rescaled_c_intensity.index = new_index\n",
    "    rescaled_c_intensity.columns = new_columns\n",
    "    rescaled_c_intensity.index.name = 'time (sec)'\n",
    "    rescaled_c_intensity.columns.name = 'position along the cilia (\\u03BCm)'\n",
    "\n",
    "    # Apply a median filter along the x-axis to suppress vertical lines, use the same filter size as before (on the original line)\n",
    "    kymograph = rescaled_c_intensity\n",
    "    # filter_size = 5\n",
    "    filtered_kymograph = median_filter(kymograph, size=(filter_size, 1))  # size=(1, width of filter)\n",
    "    corrected_kymograph = kymograph - filtered_kymograph\n",
    "    rescaled_c_intensity = corrected_kymograph\n",
    "\n",
    "    # kymograph_display_units(rescaled_c_intensity.iloc[:500], aspect_ratio)\n",
    "    kymograph_display_units(rescaled_c_intensity.iloc[:200])\n",
    "    plt.savefig(output_path + f\"kymograph_rotated_line_{i+1}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Step 4: Calculate and display the autocorrelation\n",
    "    # c = autocorrelation2D_fft_units(c_intensity_norm)\n",
    "    c = autocorrelation2D_fft_units(rescaled_c_intensity)\n",
    "    index_t = np.arange(c.shape[0]) / fps\n",
    "    index_x = np.arange(c.shape[1]) * new_spatial_resolution\n",
    "    correlation = pd.DataFrame(c, index=pd.Index(index_t, name='dt (sec)'), columns=pd.Index(index_x, name='dx (\\u03BCm)'))\n",
    "\n",
    "    # autocorrelation2D_visualization_units(correlation.iloc[:], aspect_ratio)\n",
    "    # plt.savefig(output_path + f\"autocorrelation_rotated_line_{i+1}.png\", dpi=300)\n",
    "    # plt.show()\n",
    "\n",
    "    # Calculate PSD for CBF\n",
    "    temporal_sampling_freq = fps\n",
    "    frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error = output_CBF_average(correlation, temporal_sampling_freq)\n",
    "    psd_cbf_data.append((frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error, f'Rotated Line {i+1} ({angles[i]}°)'))\n",
    "\n",
    "    # Calculate PSD for Wavelength\n",
    "    spatial_sampling_freq = 1 / pixel_size\n",
    "    # spatial_sampling_freq = 1 # because data is already in μm (?)\n",
    "    average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, wavelength, wavelength_error, primary_wavenumber, wavenumber_error = output_wavelength_average(correlation, spatial_sampling_freq)\n",
    "    psd_wavelength_data.append((average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, primary_wavenumber, wavenumber_error, wavelength, wavelength_error, f'Rotated Line {i+1} ({angles[i]}°)' ))\n",
    "\n",
    "\n",
    "# Add the original line to PSD data\n",
    "x_start, y_start = original_line[0]\n",
    "x_end, y_end = original_line[1]\n",
    "x_manual = np.array([x_start, x_end])\n",
    "y_manual = np.array([y_start, y_end])\n",
    "\n",
    "x_cilia, y_cilia = spline_generator(x_manual, y_manual, pixel_size, new_spatial_resolution, s, k)\n",
    "x_int, y_int, x_residue, y_residue, dx, dy = x_y_to_indices(x_cilia, y_cilia)\n",
    "theta = np.arctan(dx / dy) * 180 / np.pi\n",
    "box, center = assistive_box_mask(box_width, box_length)\n",
    "c_intensity = apply_box_mask(image_norm, box, theta, center, box_width, box_length, x_residue, y_residue, x_int, y_int, num_frames)\n",
    "\n",
    "c_intensity_min = np.min(c_intensity)\n",
    "c_intensity_max = np.max(c_intensity)\n",
    "c_intensity_norm = (c_intensity - c_intensity_min) / (c_intensity_max - c_intensity_min)\n",
    "\n",
    "# Step 3: Display the kymograph\n",
    "num_frames = c_intensity.shape[0]\n",
    "num_pixels = c_intensity.shape[1]\n",
    "new_index = pd.Index(np.arange(num_frames) / fps)\n",
    "new_columns = pd.Index(np.arange(num_pixels) * new_spatial_resolution)\n",
    "rescaled_c_intensity = c_intensity.copy()\n",
    "rescaled_c_intensity.index = new_index\n",
    "rescaled_c_intensity.columns = new_columns\n",
    "rescaled_c_intensity.index.name = 'time (sec)'\n",
    "rescaled_c_intensity.columns.name = 'position along the cilia (\\u03BCm)'\n",
    "\n",
    "# Apply a median filter along the x-axis to suppress vertical lines, use the same filter size as before (on the original line)\n",
    "kymograph = rescaled_c_intensity\n",
    "# filter_size = 5\n",
    "filtered_kymograph = median_filter(kymograph, size=(filter_size, 1))  # size=(1, width of filter)\n",
    "corrected_kymograph = kymograph - filtered_kymograph\n",
    "rescaled_c_intensity = corrected_kymograph\n",
    "\n",
    "# c = autocorrelation2D_fft_units(c_intensity_norm)\n",
    "c = autocorrelation2D_fft_units(rescaled_c_intensity)\n",
    "index_t = np.arange(c.shape[0]) / fps\n",
    "index_x = np.arange(c.shape[1]) * new_spatial_resolution\n",
    "correlation = pd.DataFrame(c, index=pd.Index(index_t, name='dt (sec)'), columns=pd.Index(index_x, name='dx (\\u03BCm)'))\n",
    "\n",
    "# Calculate PSD for CBF\n",
    "temporal_sampling_freq = fps\n",
    "frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error = output_CBF_average(correlation, temporal_sampling_freq)\n",
    "psd_cbf_data.insert(0, (frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error, \"Original\"))\n",
    "\n",
    "# Calculate PSD for Wavelength\n",
    "spatial_sampling_freq = 1 / pixel_size\n",
    "# spatial_sampling_freq = 1 # because data is already in μm (?)\n",
    "average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, wavelength, wavelength_error, primary_wavenumber, wavenumber_error = output_wavelength_average(correlation, spatial_sampling_freq)\n",
    "psd_wavelength_data.insert(0, (average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, primary_wavenumber, wavenumber_error, wavelength, wavelength_error, \"Original\"))\n",
    "\n",
    "# Plot combined PSD for CBF\n",
    "plt.figure(figsize=(10, 6))\n",
    "for frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error, label in psd_cbf_data:\n",
    "    plt.plot(frequencies, psd_t_norm, label=f\"{label} (CBF: {CBF:.2f} ± {CBF_error:.2f} Hz)\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Power Spectral Density (CBF)\")\n",
    "plt.title(\"Combined PSD of CBF for All Lines\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(output_path + \"Combined_PSD_CBF_with_values.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Plot combined PSD for Wavelength\n",
    "plt.figure(figsize=(10, 6))\n",
    "for average_wavenumbers, psd_x_norm, std_wavenumbers, std_psd_x, primary_wavenumber, wavenumber_error, wavelength, wavelength_error, label in psd_wavelength_data:\n",
    "    plt.plot(average_wavenumbers, psd_x_norm, label=f\"{label} (λ: {wavelength:.2f} ± {wavelength_error:.2f} μm)\")\n",
    "plt.xlabel(\"Wavenumber (1/μm)\")\n",
    "plt.ylabel(\"Power Spectral Density (Wavelength)\")\n",
    "plt.title(\"Combined PSD of Wavelength for All Lines\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(output_path + \"Combined_PSD_Wavelength_with_values.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store the new wavelength data\n",
    "new_wavelength_data = []\n",
    "new_wavelength_plots = []\n",
    "\n",
    "# Perform the same calculations for each rotated line as was done for the original line\n",
    "for i, line in enumerate([original_line] + rotated_lines):\n",
    "    label = \"Original\" if i == 0 else f\"Rotated Line {i} ({angles[i-1]}°)\" if i > 0 else f\"Rotated Line {i}\"\n",
    "    print(f\"Processing {label}...\")\n",
    "\n",
    "    # Step 1: Define a curve/spline along the selection and generate 1D representation of the ciliary array\n",
    "    x_start, y_start = line[0]\n",
    "    x_end, y_end = line[1]\n",
    "    x_manual = np.array([x_start, x_end])\n",
    "    y_manual = np.array([y_start, y_end])\n",
    "    if len(x_manual) <= k:\n",
    "        k = len(x_manual) - 1  # Reduce k to be less than the number of points\n",
    "    x_cilia, y_cilia = spline_generator(x_manual, y_manual, pixel_size, new_spatial_resolution, s, k)\n",
    "    x_int, y_int, x_residue, y_residue, dx, dy = x_y_to_indices(x_cilia, y_cilia)\n",
    "    theta = np.arctan(dx / dy) * 180 / np.pi\n",
    "    box, center = assistive_box_mask(box_width, box_length)\n",
    "    c_intensity = apply_box_mask(image_norm, box, theta, center, box_width, box_length, x_residue, y_residue, x_int, y_int, num_frames)\n",
    "\n",
    "    # Step 2: Normalize the kymograph\n",
    "    c_intensity_min = np.min(c_intensity)\n",
    "    c_intensity_max = np.max(c_intensity)\n",
    "    c_intensity_norm = (c_intensity - c_intensity_min) / (c_intensity_max - c_intensity_min)\n",
    "\n",
    "    # Step 3: Display the kymograph\n",
    "    num_frames = c_intensity.shape[0]\n",
    "    num_pixels = c_intensity.shape[1]\n",
    "    new_index = pd.Index(np.arange(num_frames) / fps)\n",
    "    new_columns = pd.Index(np.arange(num_pixels) * new_spatial_resolution)\n",
    "    rescaled_c_intensity = c_intensity.copy()\n",
    "    rescaled_c_intensity.index = new_index\n",
    "    rescaled_c_intensity.columns = new_columns\n",
    "    rescaled_c_intensity.index.name = 'time (sec)'\n",
    "    rescaled_c_intensity.columns.name = 'position along the cilia (\\u03BCm)'\n",
    "\n",
    "    # Apply a median filter along the x-axis to suppress vertical lines, use the same filter size as before (on the original line)\n",
    "    kymograph = rescaled_c_intensity\n",
    "    # filter_size = 5\n",
    "    filtered_kymograph = median_filter(kymograph, size=(filter_size, 1))  # size=(1, width of filter)\n",
    "    corrected_kymograph = kymograph - filtered_kymograph\n",
    "    rescaled_c_intensity = corrected_kymograph\n",
    "\n",
    "    # kymograph_display_units(rescaled_c_intensity.iloc[:500], aspect_ratio)\n",
    "    kymograph_display_units(rescaled_c_intensity.iloc[:200])\n",
    "    plt.savefig(output_path + f\"kymograph_rotated_line_{i+1}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Step 3: Apply a median filter and calculate autocorrelation\n",
    "    filtered_kymograph = median_filter(c_intensity_norm, size=(filter_size, 1))\n",
    "    corrected_kymograph = c_intensity_norm - filtered_kymograph\n",
    "    c = autocorrelation2D_fft_units(corrected_kymograph)\n",
    "    index_t = np.arange(c.shape[0]) / fps\n",
    "    index_x = np.arange(c.shape[1]) * new_spatial_resolution\n",
    "    correlation = pd.DataFrame(c, index=pd.Index(index_t, name='dt (sec)'), columns=pd.Index(index_x, name='dx (μm)'))\n",
    "\n",
    "    autocorrelation2D_visualization_units(correlation.iloc[:100])\n",
    "    plt.savefig(output_path + f\"autocorrelation_rotated_line_{i+1}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Step 4: Find peaks and calculate wavelength\n",
    "    y_location = 0  # Analyze at y=1\n",
    "    # peaks_w, properties = find_peaks(correlation.iloc[y_location, :], prominence=0.1)\n",
    "    peaks_w, properties = find_peaks(correlation.iloc[y_location, :], prominence=0.01)\n",
    "    if len(peaks_w) == 0:\n",
    "        print(f\"No peaks found for {label}. Skipping...\")\n",
    "        continue\n",
    "    elif len(peaks_w) > 1:\n",
    "        prominent_peak = peaks_w[1]  # Use the second peak\n",
    "    elif len(peaks_w) == 1:\n",
    "        prominent_peak = peaks_w[0]  # Use the only peak\n",
    "\n",
    "    ds_peak_1 = correlation.columns[prominent_peak]\n",
    "    wavelength = ds_peak_1\n",
    "\n",
    "    # Calculate the width at relative height 0.5\n",
    "    widths_half, width_heights_half, left_ips_half, right_ips_half = peak_widths(correlation.iloc[y_location, :], [prominent_peak],rel_height=0.5)\n",
    "    wavelength_error = widths_half[0] / 2  # Error as half of the width at 0.5\n",
    "\n",
    "    # Append data to the list\n",
    "    new_wavelength_data.append((label, wavelength, wavelength_error, peaks_w))\n",
    "\n",
    "    # Plot the autocorrelation with the prominent peak and its widths\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(correlation.columns, correlation.iloc[y_location, :], marker='o', linestyle='-', label=\"Autocorrelation\")\n",
    "    plt.plot(correlation.columns[prominent_peak], correlation.iloc[y_location, prominent_peak], \"ro\", label=\"Prominent Peak\")\n",
    "    plt.hlines(width_heights_half, correlation.columns[int(left_ips_half[0])], correlation.columns[int(right_ips_half[0])], color=\"green\", linestyle=\"--\", label=f\"Width at 0.5: {widths_half[0]:.2f} μm\")\n",
    "    plt.axvline(x=ds_peak_1, ymin=0, ymax=1, color='red', linestyle='--', label=f\"Wavelength: {wavelength:.2f} μm\")\n",
    "    plt.xlabel(\"dx (μm)\")\n",
    "    plt.ylabel(\"Autocorrelation\")\n",
    "    plt.title(f\"Autocorrelation with Peak Widths - {label}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plot_path = output_path + f\"autocorrelation_with_widths_{label.replace(' ', '_').lower()}.png\"\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Append plot path to the list\n",
    "    new_wavelength_plots.append(plot_path)\n",
    "\n",
    "# Plot combined results for the new wavelength data\n",
    "plt.figure(figsize=(10, 6))\n",
    "for label, wavelength, wavelength_error, peaks in new_wavelength_data:\n",
    "    plt.errorbar([label], [wavelength], yerr=[wavelength_error], fmt='o', label=f\"{label} (λ: {wavelength:.2f} ± {wavelength_error:.2f} μm)\")\n",
    "plt.xlabel(\"Line\")\n",
    "plt.ylabel(\"Wavelength (μm)\")\n",
    "plt.title(\"Wavelength for All Lines\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(output_path + \"combined_wavelength_results.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### It is possible to generate parallel lines to the original line, this is both to check the robustness of the CBF and wavelength results, and to obtain the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to generate a single rotated line, choose angle = 0 to get the original imported line. Or choose the best angle\n",
    "def generate_rotated_line(x_start, y_start, x_end, y_end, x_center, y_center, angle):\n",
    "    # Convert angle to radians\n",
    "    angle_rad = np.radians(angle)\n",
    "\n",
    "    # Create the original line as a NumPy array\n",
    "    original_line = np.array([[x_start, y_start], [x_end, y_end]])\n",
    "\n",
    "    # Translate the line to the origin\n",
    "    translated_line = original_line - np.array([x_center, y_center])\n",
    "\n",
    "    # Create the rotation matrix\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(angle_rad), -np.sin(angle_rad)],\n",
    "        [np.sin(angle_rad), np.cos(angle_rad)]\n",
    "    ])\n",
    "\n",
    "    # Rotate the line\n",
    "    rotated_line = np.dot(translated_line, rotation_matrix.T)\n",
    "\n",
    "    # Translate the line back to its original position\n",
    "    rotated_line += np.array([x_center, y_center])\n",
    "\n",
    "    return rotated_line\n",
    "\n",
    "# Example usage\n",
    "angle = 5.19  # Specify the desired angle compared to the original line. Found from previous analysis\n",
    "\n",
    "# strat from original line\n",
    "x_start, y_start = original_line[0]\n",
    "x_end, y_end = original_line[1]\n",
    "x_center = (x_start + x_end) / 2\n",
    "y_center = (y_start + y_end) / 2\n",
    "\n",
    "# Generate the rotated line\n",
    "rotated_line = generate_rotated_line(x_start, y_start, x_end, y_end, x_center, y_center, angle)\n",
    "\n",
    "# Calculate the angle of the rotated line with the y-axis\n",
    "rotated_x_start, rotated_y_start = rotated_line[0]\n",
    "rotated_x_end, rotated_y_end = rotated_line[1]\n",
    "rotated_angle = calculate_angle(rotated_x_start, rotated_y_start, rotated_x_end, rotated_y_end)\n",
    "\n",
    "# Plot the original and rotated line\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image[0], cmap='gray')\n",
    "plt.plot([x_start, x_end], [y_start, y_end], 'r-', label=f'Original Line')\n",
    "plt.plot(rotated_line[:, 0], rotated_line[:, 1], 'g-', label=f'Rotated Line (Angle with Y-axis: {rotated_angle:.0f}°)')\n",
    "# plt.scatter(x_center, y_center, color='blue', label='Center')\n",
    "plt.legend()\n",
    "plt.title('Original and Rotated Line')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Angle of the rotated line compared to the y-axis: {rotated_angle:.2f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to generate parallel lines\n",
    "def generate_parallel_lines(x_start, y_start, x_end, y_end, distances):\n",
    "    parallel_lines = []\n",
    "    # Calculate the slope and perpendicular vector\n",
    "    dx = x_end - x_start\n",
    "    dy = y_end - y_start\n",
    "    length = np.sqrt(dx**2 + dy**2)\n",
    "    perp_vector = np.array([-dy, dx]) / length  # Unit perpendicular vector\n",
    "\n",
    "    for distance in distances:\n",
    "        offset = distance * perp_vector\n",
    "        parallel_line = np.array([[x_start, y_start], [x_end, y_end]]) + offset\n",
    "        parallel_lines.append(parallel_line)\n",
    "    return parallel_lines\n",
    "\n",
    "# Define distances for parallel lines\n",
    "distances = [-10, -5, 5, 10]  # Adjust as needed\n",
    "\n",
    "# Generate parallel lines\n",
    "# parallel_lines = generate_parallel_lines(x_start, y_start, x_end, y_end, distances) # from original line\n",
    "parallel_lines = generate_parallel_lines(rotated_x_start, rotated_y_start, rotated_x_end, rotated_y_end, distances) # from rotated line\n",
    "\n",
    "# Plot the original and parallel lines\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image[0], cmap='gray')\n",
    "# plt.plot([x_start, x_end], [y_start, y_end], 'r-', label='Original Line')\n",
    "plt.plot([rotated_x_start, rotated_x_end], [rotated_y_start, rotated_y_end], 'r-', label=f'Rotated Line (Angle with Y-axis: {rotated_angle:.0f}°)')\n",
    "for i, line in enumerate(parallel_lines):\n",
    "    plt.plot(line[:, 0], line[:, 1], label=f'Parallel Line {i+1} (Distance: {distances[i]} px)')\n",
    "plt.scatter(x_center, y_center, color='blue', label='Center')\n",
    "plt.legend()\n",
    "plt.title('Original and Parallel Lines')\n",
    "plt.savefig(output_path + \"parallel_lines_usedforanalysis.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # OPTIONAL !!!! --> if used than change the function in the next cell to add the threshold!\n",
    "# # If the frequency peak is the wrong one, you can try to change the primary peak manually by adding a threshold\n",
    "#\n",
    "# def output_CBF_average(correlation, temporal_sampling_freq, frequency_threshold):\n",
    "#     \"\"\"\n",
    "#     Calculation of the CBF using the autocorrelation pattern by averaging over all lags in space.\n",
    "#     Errors are estimated by the full width at half maximum (FWHM).\n",
    "#     \"\"\"\n",
    "#     num_frames = correlation.shape[0]\n",
    "#     num_dx = correlation.shape[1]\n",
    "#\n",
    "#     # For space_lag = 0\n",
    "#     space_lag = 0\n",
    "#     frequencies_0, psd_t_0 = signal.welch(correlation.iloc[:, space_lag], fs=temporal_sampling_freq, nperseg=num_frames)\n",
    "#\n",
    "#     size_psd = psd_t_0.shape[0]\n",
    "#\n",
    "#     # For all space lags\n",
    "#     frequencies_all = np.zeros((num_dx, size_psd))\n",
    "#     psd_t_all = np.zeros((num_dx, size_psd))\n",
    "#\n",
    "#     frequencies_all[0, :] = frequencies_0\n",
    "#     psd_t_all[0, :] = psd_t_0\n",
    "#\n",
    "#     # Loop over space_lag values from 1 to num_dx - 1\n",
    "#     for space_lag in range(1, num_dx):\n",
    "#         frequencies, psd_t = signal.welch(correlation.iloc[:, space_lag], fs=temporal_sampling_freq, nperseg=num_frames)\n",
    "#         frequencies_all[space_lag, :] = frequencies\n",
    "#         psd_t_all[space_lag, :] = psd_t\n",
    "#\n",
    "#     # Average along the rows\n",
    "#     average_frequencies = np.mean(frequencies_all, axis=0)\n",
    "#     average_psd_t = np.mean(psd_t_all, axis=0)\n",
    "#\n",
    "#     # std along the rows\n",
    "#     std_frequencies = np.std(frequencies_all, axis=0)\n",
    "#     std_psd_t = np.std(psd_t_all, axis=0)\n",
    "#\n",
    "#     # normalization:\n",
    "#     average_psd_t = average_psd_t / np.max(average_psd_t)\n",
    "#     std_psd_t = std_psd_t / np.max(average_psd_t)\n",
    "#\n",
    "#     # Find the peaks in the psd:\n",
    "#     peaks, _ = signal.find_peaks(average_psd_t)\n",
    "#\n",
    "#     # Filter peaks based on the x-axis (frequency threshold)\n",
    "#     peaks = np.array([peak for peak in peaks if average_frequencies[peak] < frequency_threshold])\n",
    "#\n",
    "#     # identify the primary frequency that should correspond to the CBF:\n",
    "#     sorted_peaks = peaks[np.argsort(average_psd_t[peaks])][::-1]\n",
    "#     primary_peak = sorted_peaks[0] if sorted_peaks[0] < 5 else sorted_peaks[0]\n",
    "#     CBF = average_frequencies[primary_peak]\n",
    "#\n",
    "#     # Calculate FWHM\n",
    "#     half_max = average_psd_t[primary_peak] / 2\n",
    "#     left_idx = np.where(average_psd_t[:primary_peak] <= half_max)[0]\n",
    "#     right_idx = np.where(average_psd_t[primary_peak:] <= half_max)[0]\n",
    "#\n",
    "#     if len(left_idx) > 0 and len(right_idx) > 0:\n",
    "#         left_half_max = average_frequencies[left_idx[-1]]\n",
    "#         right_half_max = average_frequencies[primary_peak + right_idx[0]]\n",
    "#         fwhm = right_half_max - left_half_max\n",
    "#         CBF_error = fwhm / 2  # Using half of FWHM as the error estimate\n",
    "#     else:\n",
    "#         CBF_error = 0  # Default to 0 if FWHM cannot be determined\n",
    "#\n",
    "#     return average_frequencies, average_psd_t,std_frequencies, std_psd_t, CBF, CBF_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store PSD data\n",
    "psd_cbf_data = []\n",
    "psd_wavelength_data = []\n",
    "\n",
    "# Perform the same calculations for each rotated line as was done for the original line\n",
    "# Convert input lists to NumPy arrays before calling spline_generator\n",
    "for i, line in enumerate(parallel_lines):\n",
    "    # Step 1: Define a curve/spline along the selection and generate 1D representation of the ciliary array\n",
    "    x_start, y_start = line[0]\n",
    "    x_end, y_end = line[1]\n",
    "    # Convert to NumPy arrays\n",
    "    x_manual = np.array([x_start, x_end])\n",
    "    y_manual = np.array([y_start, y_end])\n",
    "    # Ensure the number of points is sufficient for the spline degree\n",
    "    if len(x_manual) <= k:\n",
    "        k = len(x_manual) - 1  # Reduce k to be less than the number of points\n",
    "\n",
    "    # Call spline_generator with NumPy arrays\n",
    "    x_cilia, y_cilia = spline_generator(x_manual, y_manual, pixel_size, new_spatial_resolution, s, k)\n",
    "    x_int, y_int, x_residue, y_residue, dx, dy = x_y_to_indices(x_cilia, y_cilia)\n",
    "    theta = np.arctan(dx / dy) * 180 / np.pi\n",
    "    box, center = assistive_box_mask(box_width, box_length)\n",
    "    c_intensity = apply_box_mask(image_norm, box, theta, center, box_width, box_length, x_residue, y_residue, x_int, y_int, num_frames)\n",
    "\n",
    "    # Step 2: Normalize the kymograph\n",
    "    c_intensity_min = np.min(c_intensity)\n",
    "    c_intensity_max = np.max(c_intensity)\n",
    "    c_intensity_norm = (c_intensity - c_intensity_min) / (c_intensity_max - c_intensity_min)\n",
    "\n",
    "    # Step 3: Display the kymograph\n",
    "    num_frames = c_intensity.shape[0]\n",
    "    num_pixels = c_intensity.shape[1]\n",
    "    new_index = pd.Index(np.arange(num_frames) / fps)\n",
    "    new_columns = pd.Index(np.arange(num_pixels) * new_spatial_resolution)\n",
    "    rescaled_c_intensity = c_intensity.copy()\n",
    "    rescaled_c_intensity.index = new_index\n",
    "    rescaled_c_intensity.columns = new_columns\n",
    "    rescaled_c_intensity.index.name = 'time (sec)'\n",
    "    rescaled_c_intensity.columns.name = 'position along the cilia (\\u03BCm)'\n",
    "\n",
    "    # Apply a median filter along the x-axis to suppress vertical lines, use the same filter size as before (on the original line)\n",
    "    kymograph = rescaled_c_intensity\n",
    "    # filter_size = 5\n",
    "    filtered_kymograph = median_filter(kymograph, size=(filter_size, 1))  # size=(1, width of filter)\n",
    "    corrected_kymograph = kymograph - filtered_kymograph\n",
    "    rescaled_c_intensity = corrected_kymograph\n",
    "\n",
    "    # kymograph_display_units(rescaled_c_intensity.iloc[:500], aspect_ratio)\n",
    "    kymograph_display_units(rescaled_c_intensity.iloc[:200])\n",
    "    plt.savefig(output_path + f\"kymograph_parallel_line_{i+1}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Step 4: Calculate and display the autocorrelation\n",
    "    # c = autocorrelation2D_fft_units(c_intensity_norm)\n",
    "    c = autocorrelation2D_fft_units(rescaled_c_intensity)\n",
    "    index_t = np.arange(c.shape[0]) / fps\n",
    "    index_x = np.arange(c.shape[1]) * new_spatial_resolution\n",
    "    correlation = pd.DataFrame(c, index=pd.Index(index_t, name='dt (sec)'), columns=pd.Index(index_x, name='dx (\\u03BCm)'))\n",
    "\n",
    "    # autocorrelation2D_visualization_units(correlation.iloc[:], aspect_ratio)\n",
    "    # plt.savefig(output_path + f\"autocorrelation_rotated_line_{i+1}.png\", dpi=300)\n",
    "    # plt.show()\n",
    "\n",
    "    # Calculate PSD for CBF\n",
    "    temporal_sampling_freq = fps\n",
    "    # frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error = output_CBF_average(correlation, temporal_sampling_freq)\n",
    "    #OPTIONAL --> only use the next 2 lines instead of the one above when you ran the previous cell and when there is a threshold needed...\n",
    "    frequency_threshold = 50  # Set the threshold on the x-axis (frequency) --> only lookad a freq that are lower than this\n",
    "    frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error = output_CBF_average(correlation, temporal_sampling_freq, frequency_threshold)\n",
    "\n",
    "    psd_cbf_data.append((frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error, f'Parallel Line {i+1} ({distances[i]} px)'))\n",
    "\n",
    "    # Calculate PSD for Wavelength\n",
    "    spatial_sampling_freq = 1 / pixel_size\n",
    "    # spatial_sampling_freq = 1 # because data is already in μm (?)\n",
    "    average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, wavelength, wavelength_error, primary_wavenumber, wavenumber_error = output_wavelength_average(correlation, spatial_sampling_freq)\n",
    "    psd_wavelength_data.append((average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, primary_wavenumber, wavenumber_error, wavelength, wavelength_error, f'Parallel Line {i+1} ({distances[i]} px)' ))\n",
    "\n",
    "\n",
    "# Add the original line to PSD data\n",
    "x_start, y_start = rotated_line[0]\n",
    "x_end, y_end = rotated_line[1]\n",
    "x_manual = np.array([x_start, x_end])\n",
    "y_manual = np.array([y_start, y_end])\n",
    "\n",
    "x_cilia, y_cilia = spline_generator(x_manual, y_manual, pixel_size, new_spatial_resolution, s, k)\n",
    "x_int, y_int, x_residue, y_residue, dx, dy = x_y_to_indices(x_cilia, y_cilia)\n",
    "theta = np.arctan(dx / dy) * 180 / np.pi\n",
    "box, center = assistive_box_mask(box_width, box_length)\n",
    "c_intensity = apply_box_mask(image_norm, box, theta, center, box_width, box_length, x_residue, y_residue, x_int, y_int, num_frames)\n",
    "\n",
    "c_intensity_min = np.min(c_intensity)\n",
    "c_intensity_max = np.max(c_intensity)\n",
    "c_intensity_norm = (c_intensity - c_intensity_min) / (c_intensity_max - c_intensity_min)\n",
    "\n",
    "# Step 3: Display the kymograph\n",
    "num_frames = c_intensity.shape[0]\n",
    "num_pixels = c_intensity.shape[1]\n",
    "new_index = pd.Index(np.arange(num_frames) / fps)\n",
    "new_columns = pd.Index(np.arange(num_pixels) * new_spatial_resolution)\n",
    "rescaled_c_intensity = c_intensity.copy()\n",
    "rescaled_c_intensity.index = new_index\n",
    "rescaled_c_intensity.columns = new_columns\n",
    "rescaled_c_intensity.index.name = 'time (sec)'\n",
    "rescaled_c_intensity.columns.name = 'position along the cilia (\\u03BCm)'\n",
    "\n",
    "# Apply a median filter along the x-axis to suppress vertical lines, use the same filter size as before (on the original line)\n",
    "kymograph = rescaled_c_intensity\n",
    "# filter_size = 5\n",
    "filtered_kymograph = median_filter(kymograph, size=(filter_size, 1))  # size=(1, width of filter)\n",
    "corrected_kymograph = kymograph - filtered_kymograph\n",
    "rescaled_c_intensity = corrected_kymograph\n",
    "\n",
    "# c = autocorrelation2D_fft_units(c_intensity_norm)\n",
    "c = autocorrelation2D_fft_units(rescaled_c_intensity)\n",
    "index_t = np.arange(c.shape[0]) / fps\n",
    "index_x = np.arange(c.shape[1]) * new_spatial_resolution\n",
    "correlation = pd.DataFrame(c, index=pd.Index(index_t, name='dt (sec)'), columns=pd.Index(index_x, name='dx (\\u03BCm)'))\n",
    "\n",
    "# Calculate PSD for CBF\n",
    "temporal_sampling_freq = fps\n",
    "# frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error = output_CBF_average(correlation, temporal_sampling_freq)\n",
    "#OPTIONAL\n",
    "frequency_threshold = 50  # Set the threshold on the x-axis (frequency)\n",
    "frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error = output_CBF_average(correlation, temporal_sampling_freq, frequency_threshold)\n",
    "\n",
    "psd_cbf_data.insert(0, (frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error, \"Original line\"))\n",
    "\n",
    "# Calculate PSD for Wavelength\n",
    "spatial_sampling_freq = 1 / pixel_size\n",
    "# spatial_sampling_freq = 1 # because data is already in μm (?)\n",
    "average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, wavelength, wavelength_error, primary_wavenumber, wavenumber_error = output_wavelength_average(correlation, spatial_sampling_freq)\n",
    "psd_wavelength_data.insert(0, (average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, primary_wavenumber, wavenumber_error, wavelength, wavelength_error, \"Original\"))\n",
    "\n",
    "# Plot combined PSD for CBF\n",
    "plt.figure(figsize=(10, 6))\n",
    "for frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error, label in psd_cbf_data:\n",
    "    plt.plot(frequencies, psd_t_norm, label=f\"{label} (CBF: {CBF:.2f} ± {CBF_error:.2f} Hz)\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Power Spectral Density (CBF)\")\n",
    "plt.title(\"Combined PSD of CBF for All Lines\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(output_path + \"Combined_PSD_CBF_with_values_parallel_lines.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Plot combined PSD for Wavelength\n",
    "plt.figure(figsize=(10, 6))\n",
    "for average_wavenumbers, psd_x_norm, std_wavenumbers, std_psd_x, primary_wavenumber, wavenumber_error, wavelength, wavelength_error, label in psd_wavelength_data:\n",
    "    plt.plot(average_wavenumbers, psd_x_norm, label=f\"{label} (λ: {wavelength:.2f} ± {wavelength_error:.2f} μm)\")\n",
    "plt.xlabel(\"Wavenumber (1/μm)\")\n",
    "plt.ylabel(\"Power Spectral Density (Wavelength)\")\n",
    "plt.title(\"Combined PSD of Wavelength for All Lines\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# plt.savefig(output_path + \"Combined_PSD_Wavelength_with_values_paralllel_lines.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#IF NEEDED CHANGE FILTER SIZE KYMOGRAPH\n",
    "filter_size = 50\n",
    "\n",
    "# Initialize lists to store the new wavelength data\n",
    "new_wavelength_data = []\n",
    "new_wavelength_plots = []\n",
    "\n",
    "# Perform the same calculations for each rotated line as was done for the original line\n",
    "for i, line in enumerate([rotated_line] + parallel_lines):\n",
    "    label = \"Original line\" if i == 0 else f\"Parallel Line {i} ({distances[i-1]} px)\" if i > 0 else f\"Rotated Line {i}\"\n",
    "    print(f\"Processing {label}...\")\n",
    "\n",
    "    # Step 1: Define a curve/spline along the selection and generate 1D representation of the ciliary array\n",
    "    x_start, y_start = line[0]\n",
    "    x_end, y_end = line[1]\n",
    "    x_manual = np.array([x_start, x_end])\n",
    "    y_manual = np.array([y_start, y_end])\n",
    "    if len(x_manual) <= k:\n",
    "        k = len(x_manual) - 1  # Reduce k to be less than the number of points\n",
    "    x_cilia, y_cilia = spline_generator(x_manual, y_manual, pixel_size, new_spatial_resolution, s, k)\n",
    "    x_int, y_int, x_residue, y_residue, dx, dy = x_y_to_indices(x_cilia, y_cilia)\n",
    "    theta = np.arctan(dx / dy) * 180 / np.pi\n",
    "    box, center = assistive_box_mask(box_width, box_length)\n",
    "    c_intensity = apply_box_mask(image_norm, box, theta, center, box_width, box_length, x_residue, y_residue, x_int, y_int, num_frames)\n",
    "\n",
    "    # Step 2: Normalize the kymograph\n",
    "    c_intensity_min = np.min(c_intensity)\n",
    "    c_intensity_max = np.max(c_intensity)\n",
    "    c_intensity_norm = (c_intensity - c_intensity_min) / (c_intensity_max - c_intensity_min)\n",
    "\n",
    "    # Step 3: Display the kymograph\n",
    "    num_frames = c_intensity.shape[0]\n",
    "    num_pixels = c_intensity.shape[1]\n",
    "    new_index = pd.Index(np.arange(num_frames) / fps)\n",
    "    new_columns = pd.Index(np.arange(num_pixels) * new_spatial_resolution)\n",
    "    rescaled_c_intensity = c_intensity.copy()\n",
    "    rescaled_c_intensity.index = new_index\n",
    "    rescaled_c_intensity.columns = new_columns\n",
    "    rescaled_c_intensity.index.name = 'time (sec)'\n",
    "    rescaled_c_intensity.columns.name = 'position along the cilia (\\u03BCm)'\n",
    "\n",
    "    # Apply a median filter along the x-axis to suppress vertical lines, use the same filter size as before (on the original line)\n",
    "    kymograph = rescaled_c_intensity\n",
    "    # filter_size = 5\n",
    "    filtered_kymograph = median_filter(kymograph, size=(filter_size, 1))  # size=(1, width of filter)\n",
    "    corrected_kymograph = kymograph - filtered_kymograph\n",
    "    rescaled_c_intensity = corrected_kymograph\n",
    "\n",
    "    # kymograph_display_units(rescaled_c_intensity.iloc[:500], aspect_ratio)\n",
    "    kymograph_display_units(rescaled_c_intensity.iloc[:200])\n",
    "    plt.savefig(output_path + f\"kymograph_parallel_line_{i+1}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Step 3: Apply a median filter and calculate autocorrelation\n",
    "    filtered_kymograph = median_filter(c_intensity_norm, size=(filter_size, 1))\n",
    "    corrected_kymograph = c_intensity_norm - filtered_kymograph\n",
    "    c = autocorrelation2D_fft_units(corrected_kymograph)\n",
    "    index_t = np.arange(c.shape[0]) / fps\n",
    "    index_x = np.arange(c.shape[1]) * new_spatial_resolution\n",
    "    correlation = pd.DataFrame(c, index=pd.Index(index_t, name='dt (sec)'), columns=pd.Index(index_x, name='dx (μm)'))\n",
    "\n",
    "    autocorrelation2D_visualization_units(correlation.iloc[:100])\n",
    "    plt.savefig(output_path + f\"autocorrelation_parallel_line_{i+1}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Step 4: Find peaks and calculate wavelength\n",
    "    y_location = 1  # Analyze at y=1\n",
    "    # peaks_w, properties = find_peaks(correlation.iloc[y_location, :], prominence=0.008)\n",
    "    peaks_w, properties = find_peaks(correlation.iloc[y_location, :], prominence=0.0005)\n",
    "    peaks_w = [peak for peak in peaks_w if correlation.columns[peak] > 8 and correlation.columns[peak] < 11]  # Filter peaks based on wavelength range\n",
    "    if len(peaks_w) == 0:\n",
    "        print(f\"No peaks found for {label}. Skipping...\")\n",
    "        continue\n",
    "    elif len(peaks_w) > 1:\n",
    "        prominent_peak = peaks_w[1]  # Use the second peak\n",
    "    elif len(peaks_w) == 2:\n",
    "        prominent_peak = peaks_w[2]  # Use the second peak\n",
    "    elif len(peaks_w) == 1:\n",
    "        prominent_peak = peaks_w[0]  # Use the only peak\n",
    "\n",
    "    ds_peak_1 = correlation.columns[prominent_peak]\n",
    "    wavelength = ds_peak_1\n",
    "\n",
    "    # Calculate the width at relative height 0.5\n",
    "    widths_half, width_heights_half, left_ips_half, right_ips_half = peak_widths(correlation.iloc[y_location, :], [prominent_peak],rel_height=0.5)\n",
    "    wavelength_error = widths_half[0] / 2  # Error as half of the width at 0.5\n",
    "    wavelength_error = wavelength_error * pixel_size  # Convert to μm\n",
    "    widths_half = widths_half * pixel_size  # Convert to μm\n",
    "\n",
    "    # Append data to the list\n",
    "    new_wavelength_data.append((label, wavelength, wavelength_error, peaks_w))\n",
    "\n",
    "    # Plot the autocorrelation with the prominent peak and its widths\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(correlation.columns, correlation.iloc[y_location, :], marker='o', linestyle='-', label=\"Autocorrelation\")\n",
    "    plt.plot(correlation.columns[prominent_peak], correlation.iloc[y_location, prominent_peak], \"ro\", label=\"Prominent Peak\")\n",
    "    plt.hlines(width_heights_half, correlation.columns[int(left_ips_half[0])], correlation.columns[int(right_ips_half[0])], color=\"green\", linestyle=\"--\", label=f\"Width at 0.5: {widths_half[0]:.2f} μm\")\n",
    "    plt.axvline(x=ds_peak_1, ymin=0, ymax=1, color='red', linestyle='--', label=f\"Wavelength: {wavelength:.2f} μm\")\n",
    "    plt.xlabel(\"dx (μm)\")\n",
    "    plt.ylabel(\"Autocorrelation\")\n",
    "    plt.title(f\"Autocorrelation with Peak Widths - {label}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plot_path = output_path + f\"autocorrelation_with_widths_{label.replace(' ', '_').lower()}.png\"\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Append plot path to the list\n",
    "    new_wavelength_plots.append(plot_path)\n",
    "\n",
    "# Plot combined results for the new wavelength data\n",
    "plt.figure(figsize=(10, 6))\n",
    "for label, wavelength, wavelength_error, peaks in new_wavelength_data:\n",
    "    plt.errorbar([label], [wavelength], yerr=[wavelength_error], fmt='o', label=f\"{label} (λ: {wavelength:.2f} ± {wavelength_error:.2f} μm)\")\n",
    "plt.xlabel(\"Line\")\n",
    "plt.ylabel(\"Wavelength (μm)\")\n",
    "plt.title(\"Wavelength for All Lines\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(output_path + \"combined_wavelength_results_parallel.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If the results of the parallel lines are good, save the results in a dataframe and the save as csv file\n",
    "wavelength_df = pd.DataFrame(new_wavelength_data, columns=['Line', 'Wavelength (μm)', 'Wavelength Error (μm)', 'Peaks'])\n",
    "wavelength_df['Wavelength (μm)'] = wavelength_df['Wavelength (μm)'].astype(float)\n",
    "wavelength_df['Wavelength Error (μm)'] = wavelength_df['Wavelength Error (μm)'].astype(float)\n",
    "wavelength_df['Peaks'] = wavelength_df['Peaks'].apply(lambda x: ', '.join(map(str, x)))\n",
    "# wavelength_df.to_csv(output_path + \"wavelength_results_parallel.csv\", index=False)\n",
    "\n",
    "\n",
    "# Create an empty DataFrame to store the results for the CBF\n",
    "cbf_results = pd.DataFrame(columns=[\"Line\", \"CBF (Hz)\", \"CBF Error (Hz)\"])\n",
    "# Iterate through the psd_cbf_data list and extract the relevant values\n",
    "for _, _, _, _, CBF, CBF_error, label in psd_cbf_data:\n",
    "    cbf_results = pd.concat([cbf_results, pd.DataFrame({\"Line\": [label], \"CBF (Hz)\": [CBF], \"CBF Error (Hz)\": [CBF_error]})], ignore_index=True)\n",
    "# Save the DataFrame to a CSV file\n",
    "# output_csv_path = output_path + \"CBF_results.csv\"\n",
    "# cbf_results.to_csv(output_csv_path, index=False)\n",
    "# print(f\"CBF results saved to {output_csv_path}\")\n",
    "\n",
    "\n",
    "# From wavelength_df and cbf_results add together the wavelenght and CBF data and add the wave velocity by multiplying the CBF and the wavelength\n",
    "# Merge the two DataFrames on the \"Line\" column\n",
    "merged_df = pd.merge(wavelength_df, cbf_results, on=\"Line\", how=\"outer\")\n",
    "# Calculate the wave velocity\n",
    "merged_df[\"Wave Velocity (μm/s)\"] = merged_df[\"Wavelength (μm)\"] * merged_df[\"CBF (Hz)\"]\n",
    "# Save the merged DataFrame to a CSV file\n",
    "output_csv_path = output_path + \"All_MW_results.csv\"\n",
    "merged_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# # Calculate the mean and standard error of the mean (SEM) for the wavelength and CBF\n",
    "# mean_wavelength = merged_df[\"Wavelength (μm)\"].mean()\n",
    "# std_wavelength = merged_df[\"Wavelength (μm)\"].std()\n",
    "# sem_wavelength = std_wavelength / np.sqrt(len(merged_df[\"Wavelength (μm)\"]))\n",
    "# mean_cbf = merged_df[\"CBF (Hz)\"].mean()\n",
    "# std_cbf = merged_df[\"CBF (Hz)\"].std()\n",
    "# sem_cbf = std_cbf / np.sqrt(len(merged_df[\"CBF (Hz)\"]))\n",
    "# # Save the mean and SEM to a CSV file\n",
    "# mean_sem_df = pd.DataFrame({\n",
    "#     \"Mean Wavelength (μm)\": [mean_wavelength],\n",
    "#     \"SEM Wavelength (μm)\": [sem_wavelength],\n",
    "#     \"Mean CBF (Hz)\": [mean_cbf],\n",
    "#     \"SEM CBF (Hz)\": [sem_cbf]\n",
    "# })\n",
    "# mean_sem_df.to_csv(output_path + \"mean_sem_results.csv\", index=False)\n",
    "\n",
    "\n",
    "# Create a dataframe with the parameters and save as csv file\n",
    "parameters_df = pd.DataFrame({ 'File Name': file_name,\n",
    "                               'Pixel Size (μm)': pixel_size,\n",
    "                               'New Spatial Resolution (μm)': new_spatial_resolution,\n",
    "                               'FPS': fps,\n",
    "                               'Filter Size (median filter kymograph)': filter_size,\n",
    "                               'Aspect Ratio': aspect_ratio,\n",
    "                               'Number of Frames': num_frames,\n",
    "                               'Angle of rotated line with Y-axis (degrees)': rotated_angle,\n",
    "                               'Length of lines (px)': np.sqrt((x_end - x_start)**2 + (y_end - y_start)**2),\n",
    "                               'Length of lines (μm)': np.sqrt((x_end - x_start)**2 + (y_end - y_start)**2) * pixel_size,\n",
    "                               'Distance between parallel lines (px)': 5,\n",
    "                               'Distance between parallel lines (μm)': 5 * pixel_size},\n",
    "                               index=[0])\n",
    "parameters_df.to_csv(output_path + \"parameters.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### When having found the perfectly rotated line (wavelength minimized = angle of 90 degrees with wave propagation direction), you can use the following code to get the wave properties with that rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to generate a single rotated line\n",
    "def generate_rotated_line(x_start, y_start, x_end, y_end, x_center, y_center, angle):\n",
    "    # Convert angle to radians\n",
    "    angle_rad = np.radians(angle)\n",
    "\n",
    "    # Create the original line as a NumPy array\n",
    "    original_line = np.array([[x_start, y_start], [x_end, y_end]])\n",
    "\n",
    "    # Translate the line to the origin\n",
    "    translated_line = original_line - np.array([x_center, y_center])\n",
    "\n",
    "    # Create the rotation matrix\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(angle_rad), -np.sin(angle_rad)],\n",
    "        [np.sin(angle_rad), np.cos(angle_rad)]\n",
    "    ])\n",
    "\n",
    "    # Rotate the line\n",
    "    rotated_line = np.dot(translated_line, rotation_matrix.T)\n",
    "\n",
    "    # Translate the line back to its original position\n",
    "    rotated_line += np.array([x_center, y_center])\n",
    "\n",
    "    return rotated_line\n",
    "\n",
    "# Example usage\n",
    "angle = 0.  # Specify the desired angle compared to the original line\n",
    "rotated_line = generate_rotated_line(x_start, y_start, x_end, y_end, x_center, y_center, angle)\n",
    "\n",
    "# Calculate the angle of the rotated line with the y-axis\n",
    "rotated_x_start, rotated_y_start = rotated_line[0]\n",
    "rotated_x_end, rotated_y_end = rotated_line[1]\n",
    "rotated_angle = calculate_angle(rotated_x_start, rotated_y_start, rotated_x_end, rotated_y_end)\n",
    "\n",
    "# Plot the original and rotated line\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image[0], cmap='gray')\n",
    "plt.plot([x_start, x_end], [y_start, y_end], 'r-', label=f'Original Line')\n",
    "plt.plot(rotated_line[:, 0], rotated_line[:, 1], 'g-', label=f'Rotated Line (Angle with Y-axis: {rotated_angle:.0f}°)')\n",
    "plt.scatter(x_center, y_center, color='blue', label='Center')\n",
    "plt.legend()\n",
    "plt.title('Original and Rotated Line')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Angle of the rotated line compared to the y-axis: {rotated_angle:.2f}°\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the kymograph for the rotated line\n",
    "x_manual = rotated_line[:, 0]\n",
    "y_manual = rotated_line[:, 1]\n",
    "x_cilia, y_cilia = spline_generator(x_manual, y_manual, pixel_size2, new_spatial_resolution, s, k)\n",
    "x_int, y_int, x_residue, y_residue, dx, dy = x_y_to_indices(x_cilia, y_cilia)\n",
    "theta = np.arctan(dx / dy) * 180 / np.pi\n",
    "box, center = assistive_box_mask(box_width, box_length)\n",
    "c_intensity = apply_box_mask(image_norm, box, theta, center, box_width, box_length, x_residue, y_residue, x_int, y_int, num_frames)\n",
    "\n",
    "# Normalize the kymograph\n",
    "c_intensity_min = np.min(c_intensity)\n",
    "c_intensity_max = np.max(c_intensity)\n",
    "c_intensity_norm = (c_intensity - c_intensity_min) / (c_intensity_max - c_intensity_min)\n",
    "\n",
    "# Rescale the kymograph\n",
    "num_frames = c_intensity.shape[0]\n",
    "num_pixels = c_intensity.shape[1]\n",
    "new_index = pd.Index(np.arange(num_frames) / fps)\n",
    "new_columns = pd.Index(np.arange(num_pixels) * new_spatial_resolution)\n",
    "rescaled_c_intensity = c_intensity.copy()\n",
    "rescaled_c_intensity.index = new_index\n",
    "rescaled_c_intensity.columns = new_columns\n",
    "rescaled_c_intensity.index.name = 'time (sec)'\n",
    "rescaled_c_intensity.columns.name = 'position along the cilia (\\u03BCm)'\n",
    "\n",
    "# Plot the kymograph\n",
    "aspect_ratio = 50\n",
    "# kymograph_display_units(rescaled_c_intensity.iloc[:], aspect_ratio)\n",
    "kymograph_display_units(rescaled_c_intensity.iloc[800:1000])\n",
    "plt.savefig(output_path + \"kymograph_rotated_line.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Filter the kymograph\n",
    "filter_size = 10\n",
    "filtered_kymograph = median_filter(rescaled_c_intensity, size=(filter_size, 1))\n",
    "corrected_kymograph = rescaled_c_intensity - filtered_kymograph\n",
    "\n",
    "# Plot original, filtered, and corrected kymographs\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax1.imshow(rescaled_c_intensity, cmap='grey', aspect='auto')\n",
    "ax1.set_title('Original Kymograph')\n",
    "ax2.imshow(filtered_kymograph, cmap='grey', aspect='auto')\n",
    "ax2.set_title(f'Filtered Kymograph (median, ({filter_size},1))')\n",
    "ax3.imshow(corrected_kymograph, cmap='grey', aspect='auto')\n",
    "ax3.set_title('Corrected Kymograph')\n",
    "plt.savefig(output_path + \"filtered_kymograph_rotated_line.png\")\n",
    "plt.show()\n",
    "\n",
    "# Save the corrected kymograph\n",
    "corrected_kymograph.to_pickle(output_path + \"corrected_kymograph_rotated_line.pkl\")\n",
    "\n",
    "# visualize only a part of the corrected kymograph\n",
    "fig, ax = plt.subplots(figsize=(5, 6))\n",
    "ax.imshow(corrected_kymograph.iloc[800:1000, 14:30], cmap='gray', aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot the autocorrelation\n",
    "c = autocorrelation2D_fft_units(corrected_kymograph)\n",
    "index_t = np.arange(c.shape[0]) / fps\n",
    "index_x = np.arange(c.shape[1]) * new_spatial_resolution\n",
    "correlation = pd.DataFrame(c, index=pd.Index(index_t, name='dt (sec)'), columns=pd.Index(index_x, name='dx (μm)'))\n",
    "# autocorrelation2D_visualization_units(correlation.iloc[:], aspect_ratio)\n",
    "autocorrelation2D_visualization_units(correlation.iloc[:100])\n",
    "plt.savefig(output_path + \"autocorrelation_rotated_line.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # If only a part of the distance of the kymograph is good/clear, then you can select a segment of the kymograph to display and analyze.\n",
    "#\n",
    "# # Display a segment of the kymograph for a specific range of distances\n",
    "# distance_start = 14  # Start of the distance range (in μm)\n",
    "# distance_end = 30    # End of the distance range (in μm)\n",
    "#\n",
    "# # Select the segment of the kymograph\n",
    "# kymograph_segment = corrected_kymograph.loc[:, (corrected_kymograph.columns >= distance_start) & (corrected_kymograph.columns <= distance_end)]\n",
    "#\n",
    "# # kymograph_segment = corrected_kymograph.loc[:, :]\n",
    "#\n",
    "# # Plot the kymograph segment\n",
    "# # kymograph_display_units(kymograph_segment, aspect_ratio)\n",
    "# kymograph_display_units(kymograph_segment)\n",
    "# plt.savefig(output_path + \"kymograph_segment.png\", dpi=300)\n",
    "# plt.show()\n",
    "#\n",
    "# fig, ax = plt.subplots(figsize=(5, 6))\n",
    "# ax.imshow(kymograph_segment.iloc[800:1000, :], cmap='gray', aspect='auto')\n",
    "# plt.show()\n",
    "#\n",
    "# # Save the kymograph segment\n",
    "# kymograph_segment.to_pickle(output_path + \"kymograph_segment.pkl\")\n",
    "#\n",
    "# # Calculate and plot the autocorrelation of the kymograph segment\n",
    "# c_segment = autocorrelation2D_fft_units(kymograph_segment)\n",
    "# index_t_segment = np.arange(c_segment.shape[0]) / fps\n",
    "# index_x_segment = np.arange(c_segment.shape[1]) * new_spatial_resolution\n",
    "# correlation_segment = pd.DataFrame(c_segment, index=pd.Index(index_t_segment, name='dt (sec)'), columns=pd.Index(index_x_segment, name='dx (μm)'))\n",
    "#\n",
    "# # Plot the autocorrelation of the segment\n",
    "# # autocorrelation2D_visualization_units(correlation_segment.iloc[:], aspect_ratio)\n",
    "# autocorrelation2D_visualization_units(correlation_segment.iloc[:])\n",
    "# plt.savefig(output_path + \"autocorrelation_kymograph_segment.png\", dpi=300)\n",
    "# plt.show()\n",
    "#\n",
    "# fig, ax = plt.subplots(figsize=(5, 6))\n",
    "# ax.imshow(correlation_segment.iloc[:, :], cmap='gray', aspect='auto')\n",
    "# plt.show()\n",
    "#\n",
    "# # If you want to use this segment for further analysis, then run the following code:\n",
    "# # kymograph = kymograph_segment\n",
    "# # correlation = correlation_segment\n",
    "# # c = c_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # RUN ONLY IF YOU WANT TO CHANGE THE CHOSEN PEAKS\n",
    "# def output_CBF_average(correlation, temporal_sampling_freq):\n",
    "#     \"\"\"\n",
    "#     Calculation of the CBF using the autocorrelation pattern by averaging over all lags in space.\n",
    "#     Errors are estimated by the full width at half maximum (FWHM).\n",
    "#     \"\"\"\n",
    "#\n",
    "#     num_frames = correlation.shape[0]\n",
    "#     num_dx = correlation.shape[1]\n",
    "#\n",
    "#     # For space_lag = 0\n",
    "#     space_lag = 0\n",
    "#     frequencies_0, psd_t_0 = signal.welch(correlation.iloc[:, space_lag], fs=temporal_sampling_freq, nperseg=num_frames)\n",
    "#\n",
    "#     size_psd = psd_t_0.shape[0]\n",
    "#\n",
    "#     # For all space lags\n",
    "#     frequencies_all = np.zeros((num_dx, size_psd))\n",
    "#     psd_t_all = np.zeros((num_dx, size_psd))\n",
    "#\n",
    "#     frequencies_all[0, :] = frequencies_0\n",
    "#     psd_t_all[0, :] = psd_t_0\n",
    "#\n",
    "#     # Loop over space_lag values from 1 to num_dx - 1\n",
    "#     for space_lag in range(1, num_dx):\n",
    "#         # Calculate power spectral density using Welch's method\n",
    "#         frequencies, psd_t = signal.welch(correlation.iloc[:, space_lag], fs=temporal_sampling_freq, nperseg=num_frames)\n",
    "#\n",
    "#         # Store the results\n",
    "#         frequencies_all[space_lag, :] = frequencies\n",
    "#         psd_t_all[space_lag, :] = psd_t\n",
    "#\n",
    "#     # Average along the rows\n",
    "#     average_frequencies = np.mean(frequencies_all, axis=0)\n",
    "#     average_psd_t = np.mean(psd_t_all, axis=0)\n",
    "#\n",
    "#     # std along the rows\n",
    "#     std_frequencies = np.std(frequencies_all, axis=0)\n",
    "#     std_psd_t = np.std(psd_t_all, axis=0)\n",
    "#\n",
    "#     # normalization:\n",
    "#     average_psd_t = average_psd_t / np.max(average_psd_t)\n",
    "#     std_psd_t = std_psd_t / np.max(average_psd_t)\n",
    "#\n",
    "#     # Find the peaks in the psd:\n",
    "#     peaks, _ = signal.find_peaks(average_psd_t)\n",
    "#\n",
    "#     # identify the primary frequency that should correspond to the CBF:\n",
    "#     sorted_peaks = peaks[np.argsort(average_psd_t[peaks])][::-1]\n",
    "#     primary_peak = sorted_peaks[1] if sorted_peaks[0] < 5 else sorted_peaks[0]\n",
    "#     CBF = average_frequencies[primary_peak]\n",
    "#\n",
    "#     # Calculate FWHM\n",
    "#     half_max = average_psd_t[primary_peak] / 2\n",
    "#     left_idx = np.where(average_psd_t[:primary_peak] <= half_max)[0]\n",
    "#     right_idx = np.where(average_psd_t[primary_peak:] <= half_max)[0]\n",
    "#\n",
    "#     if len(left_idx) > 0 and len(right_idx) > 0:\n",
    "#         left_half_max = average_frequencies[left_idx[-1]]\n",
    "#         right_half_max = average_frequencies[primary_peak + right_idx[0]]\n",
    "#         fwhm = right_half_max - left_half_max\n",
    "#         CBF_error = fwhm / 2  # Using half of FWHM as the error estimate\n",
    "#     else:\n",
    "#         CBF_error = 0  # Default to 0 if FWHM cannot be determined\n",
    "#\n",
    "#     return average_frequencies, average_psd_t, std_frequencies, std_psd_t, CBF, CBF_error\n",
    "#\n",
    "#\n",
    "# def output_wavelength_average(correlation, spatial_sampling_freq):\n",
    "#     \"\"\"\n",
    "#     Calculation of the wavelength using the autocorrelation pattern by averaging over all lags in time.\n",
    "#     Errors are estimated by the full width at half maximum (FWHM).\n",
    "#     \"\"\"\n",
    "#\n",
    "#     N = correlation.shape[1]\n",
    "#     num_dt = correlation.shape[0]\n",
    "#\n",
    "#     # For time_lag = 0\n",
    "#     time_lag = 0\n",
    "#     wavenumbers_0, psd_x_0 = signal.welch(correlation.iloc[time_lag, :], fs=spatial_sampling_freq, nperseg=N)\n",
    "#\n",
    "#     size_psd = psd_x_0.shape[0]\n",
    "#\n",
    "#     wavenumbers_all = np.zeros((num_dt, size_psd))\n",
    "#     psd_x_all = np.zeros((num_dt, size_psd))\n",
    "#\n",
    "#     wavenumbers_all[0, :] = wavenumbers_0\n",
    "#     psd_x_all[0, :] = psd_x_0\n",
    "#\n",
    "#     for time_lag in range(1, num_dt):\n",
    "#         # Calculate power spectral density using Welch's method\n",
    "#         wavenumbers, psd_x = signal.welch(correlation.iloc[time_lag, :], fs=spatial_sampling_freq, nperseg=N)\n",
    "#\n",
    "#         # Store the results\n",
    "#         wavenumbers_all[time_lag, :] = wavenumbers\n",
    "#         psd_x_all[time_lag, :] = psd_x\n",
    "#\n",
    "#     # Average along the rows\n",
    "#     average_wavenumbers = np.mean(wavenumbers_all, axis=0)\n",
    "#     average_psd_x = np.mean(psd_x_all, axis=0)\n",
    "#\n",
    "#     # std along the rows\n",
    "#     std_wavenumbers = np.std(wavenumbers_all, axis=0)\n",
    "#     std_psd_x = np.std(psd_x_all, axis=0)\n",
    "#\n",
    "#     # normalization:\n",
    "#     average_psd_x = average_psd_x / np.mean(average_psd_x)\n",
    "#     std_psd_x = std_psd_x / np.mean(average_psd_x)\n",
    "#\n",
    "#     peaks, _ = signal.find_peaks(average_psd_x)\n",
    "#     sorted_peaks = peaks[np.argsort(average_psd_x[peaks])][::-1]\n",
    "#     primary_peak = sorted_peaks[1] if sorted_peaks[0] <= 0 else sorted_peaks[0]\n",
    "#     primary_wavenumber = average_wavenumbers[primary_peak]\n",
    "#\n",
    "#     # Calculate FWHM\n",
    "#     half_max = average_psd_x[primary_peak] / 2\n",
    "#     left_idx = np.where(average_psd_x[:primary_peak] <= half_max)[0]\n",
    "#     right_idx = np.where(average_psd_x[primary_peak:] <= half_max)[0]\n",
    "#\n",
    "#     if len(left_idx) > 0 and len(right_idx) > 0:\n",
    "#         left_half_max = average_wavenumbers[left_idx[-1]]\n",
    "#         right_half_max = average_wavenumbers[primary_peak + right_idx[0]]\n",
    "#         fwhm = right_half_max - left_half_max\n",
    "#         wavenumber_error = fwhm / 2  # Using half of FWHM as the error estimate\n",
    "#     else:\n",
    "#         wavenumber_error = 0  # Default to 0 if FWHM cannot be determined\n",
    "#\n",
    "#     wavelength = 1 / primary_wavenumber\n",
    "#     wavelength_error = (1 / primary_wavenumber) ** 2 * wavenumber_error\n",
    "#\n",
    "#     return average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, wavelength, wavelength_error, primary_wavenumber, wavenumber_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CBF by averaging over all space lags:\n",
    "temporal_sampling_freq = fps\n",
    "frequencies, psd_t_norm, std_frequencies, std_psd_t, CBF, CBF_error = output_CBF_average(correlation, temporal_sampling_freq)\n",
    "\n",
    "# Plotting of PSD with CBF:\n",
    "plot_CBF(frequencies, psd_t_norm, std_psd_t, CBF, CBF_error)\n",
    "plt.savefig(output_path + \"PSD_CBF.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# λ by averaging over all space lags:\n",
    "# spatial_sampling_freq = 1 / pixel_size  # pixel/μm\n",
    "spatial_sampling_freq = 1 # because data is already in μm (?)\n",
    "average_wavenumbers, average_psd_x, std_wavenumbers, std_psd_x, wavelength, wavelength_error, primary_wavenumber, wavenumber_error = output_wavelength_average(correlation.iloc[400:,:], spatial_sampling_freq)\n",
    "\n",
    "# Plotting of PSD with λ:\n",
    "plot_wavelength(average_wavenumbers, average_psd_x, std_psd_x, primary_wavenumber, wavenumber_error, wavelength, wavelength_error)\n",
    "plt.savefig(output_path + \"PSD_wavelength.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Alternative ways to get the wavelength from the autocorrelation and kymograph\n",
    "\n",
    "#### Because for the Paramecium data we cannot plot a very long line over time, we don't have many wavelenghts in the field of view to average over. This results in that the power spectral density does sometimes not give a very good result because there are not enough wavelengths visible next to each other (dx is too short, only 2 or 3 waves visible at the same time)\n",
    "\n",
    "One method to get the wavelength for this data: look at the autocorrelation of the kymograph and find the peaks in the autocorrelation for a specific timepoint (plot autocorrelation intensity in 1D for y=0). The distance between the peaks gives the wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# autocorrelation2D_visualization_units(correlation.iloc[:], aspect_ratio)\n",
    "autocorrelation2D_visualization_units(correlation.iloc[:100])\n",
    "plt.savefig(output_path + \"autocorrelation_rotated_line.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# plot a part of the autocorrelation plot\n",
    "fig, ax = plt.subplots(figsize=(5, 6))\n",
    "ax.imshow(correlation.iloc[0:100, :], cmap='gray', aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "point_y = 1 # the timepoint you want to analyze (choose y=0 or y=1 to get the most clear peaks (top of the autocorrelation plot))\n",
    "\n",
    "# find peaks in the autocorrelation in space at timepoint y=0\n",
    "peaks_w, _ = signal.find_peaks(correlation.iloc[point_y, :], prominence=0.1)\n",
    "# peaks_w, _ = signal.find_peaks(correlation.iloc[0, :], prominence=0.02)\n",
    "print(\"detected peak indices wavelength\", peaks_w)\n",
    "print(peaks_w[1:])\n",
    "# ds_peak, = correlation.columns[peaks_w]\n",
    "# print(\"space between nodes: \", ds_peak)\n",
    "# wavelength_MW = ds_peak\n",
    "# print(\"wavelength (\\u03BCm): \", wavelength_MW)\n",
    "\n",
    "\n",
    "# # Plot the autocorrelation for a specific timepoint (y=0)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(correlation.iloc[1, :], marker='o', linestyle='-')\n",
    "# # plt.axvline(x=ds_peak, ymin=0, ymax=1, color='red', linestyle='--')\n",
    "# plt.axvline(x=peaks_w, ymin=0, ymax=1, color='red', linestyle='--')\n",
    "# # plt.axvline(x=ds_peak, ymin=0, ymax=1, color='red', linestyle='--')\n",
    "# plt.xlabel('dx (μm)')\n",
    "# plt.ylabel('Autocorrelation')\n",
    "# plt.title('Autocorrelation at dt=0 (y=0)')\n",
    "# plt.grid(True)\n",
    "# plt.savefig(output_path + \"autocorrelation_y0_rotated_line.png\", dpi=300)\n",
    "# plt.show()\n",
    "\n",
    "# Plot the autocorrelation for a specific timepoint (y=0)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(correlation.iloc[point_y, :], marker='o', linestyle='-')\n",
    "\n",
    "# Plot vertical lines for each detected peak\n",
    "for peak in peaks_w:\n",
    "    plt.axvline(x=correlation.columns[peak], ymin=0, ymax=1, color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('dx (μm)')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.title('Autocorrelation at dt=0 (y=0)')\n",
    "plt.grid(True)\n",
    "plt.savefig(output_path + \"autocorrelation_y0_rotated_line.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Another way to get the wavelength for this data: look directly at the kymograph and find the peaks in the kymograph for a specific timepoint (plot kymograph intensity in 1D for y=0). The distance between the peaks gives the wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize only a part of the NOT corrected kymograph\n",
    "fig, ax = plt.subplots(figsize=(5, 6))\n",
    "ax.imshow(kymograph.iloc[850:900, :], cmap='gray', aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# visualize only a part of the corrected kymograph\n",
    "fig, ax = plt.subplots(figsize=(5, 6))\n",
    "ax.imshow(corrected_kymograph.iloc[850:900, :], cmap='gray', aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# plot the kymograph intensity for a specific timepoint in 1D (y=0)\n",
    "timepoint_y = 890 # the timepoint you want to analyze\n",
    "\n",
    "# # find peaks in the kymograph intensity in space at timepoint_y\n",
    "# peaks_w, _ = signal.find_peaks(kymograph.iloc[timepoint_y, :], prominence=0.1)\n",
    "# # peaks_w, _ = signal.find_peaks(kymograph.iloc[0, :], prominence=0.02)\n",
    "# print(\"detected peak indices wavelength\", peaks_w)\n",
    "# print(peaks_w[1:])\n",
    "# # ds_peak, = kymograph.columns[peaks_w]\n",
    "# # print(\"space between nodes: \", ds_peak)\n",
    "# # wavelength_MW = ds_peak\n",
    "# # print(\"wavelength (\\u03BCm): \", wavelength_MW)\n",
    "#\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(kymograph.iloc[timepoint_y, :], marker='o', linestyle='-')\n",
    "# plt.axvline(x=kymograph.columns[peaks_w[1]], ymin=0, ymax=1, color='red', linestyle='--')\n",
    "# plt.xlabel('dx (μm)')\n",
    "# plt.ylabel('Kymograph Intensity')\n",
    "# plt.title('Kymograph Intensity 1D')\n",
    "# plt.show()\n",
    "\n",
    "# Invert the kymograph intensity for the specified timepoint\n",
    "inverted_data = -kymograph.iloc[timepoint_y, :]\n",
    "# Find peaks in the inverted data (equivalent to finding valleys in the original data)\n",
    "valleys_w, _ = signal.find_peaks(inverted_data, prominence=0.1)\n",
    "# Print the detected valley indices\n",
    "print(\"Detected valley indices (wavelength):\", valleys_w)\n",
    "print(valleys_w[1:])\n",
    "\n",
    "# Plot the inverted kymograph intensity for a specific timepoint\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(inverted_data, marker='o', linestyle='-')\n",
    "# Plot vertical lines for each detected valley\n",
    "for valley in valleys_w:\n",
    "    plt.axvline(x=kymograph.columns[valley], ymin=0, ymax=1, color='red', linestyle='--')\n",
    "plt.xlabel('dx (μm)')\n",
    "plt.ylabel('Inverted Kymograph Intensity')\n",
    "plt.title('Inverted Kymograph Intensity 1D')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "#### Calculate frequency and wavelength by finding the autocorrelation and the corresponding dt and dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize the kymograph:\n",
    "corrected_kymograph_min  = np.min(corrected_kymograph)\n",
    "corrected_kymograph_max  = np.max(corrected_kymograph)\n",
    "corrected_kymograph_norm = (corrected_kymograph - corrected_kymograph_min)/(corrected_kymograph_max - corrected_kymograph_min)\n",
    "\n",
    "corrected_kymograph_norm.to_pickle(output_path + \"corrected_kymograph_norm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autocorrelation2D_visualization_units(c):\n",
    "    \"\"\"\n",
    "    Displays the autocorrelation in space (μm) and time (sec).\n",
    "    Aspect ratio is adjusted considering that usual fps is in the magnitude of 1000.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(c, aspect = 100/1, origin = 'lower', extent=[c.columns[0], c.columns[-1], c.index[0], c.index[-1]], cmap = mpl.colormaps.get_cmap('jet'))\n",
    "\n",
    "    plt.title('2D Autocorrelation', fontsize = 13)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel('dx (\\u03BCm)', fontsize = 10)\n",
    "    plt.ylabel('dt (sec)', fontsize = 10)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save c_intensity:\n",
    "rescaled_c_intensity.to_pickle(output_path + \"rescaled_c_intensity.pkl\")\n",
    "\n",
    "c = autocorrelation2D_fft_units(corrected_kymograph_norm.iloc[:200,:])\n",
    "# c = autocorrelation2D_fft_units(corrected_kymograph_norm)\n",
    "\n",
    "index_t = np.arange(c.shape[0])\n",
    "index_x = np.arange(c.shape[1])\n",
    "# Turning c to dataframe:\n",
    "# correlation = pd.DataFrame(data = c, index = pd.Index(index_t/fps), columns = pd.Index(index_x*pixel_size))\n",
    "correlation = pd.DataFrame(data = c, index = pd.Index(index_t/fps), columns = pd.Index(index_x))\n",
    "correlation.index.name = 'dt (sec)'\n",
    "correlation.columns.name = 'dx (\\u03BCm)'\n",
    "\n",
    "# visualization\n",
    "autocorrelation2D_visualization_units(correlation)\n",
    "plt.savefig(output_path + \"autocorrelation_corrected.png\", dpi=300)\n",
    "\n",
    "# Save correlation:\n",
    "correlation.to_pickle(output_path + \"correlation_corrected.pkl\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_value = correlation.min().min()  # Minimum value\n",
    "max_value = correlation.max().max()  # Maximum value\n",
    "\n",
    "print(min_value)\n",
    "print(max_value)\n",
    "\n",
    "print(max_value - min_value)\n",
    "correlation_normalized = (correlation - min_value) / (max_value - min_value)\n",
    "# correlation_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualization\n",
    "autocorrelation2D_visualization_units(correlation_normalized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_location = 1  # The timepoint you want to analyze (choose y=0 or y=1 to get the most clear peaks (top of the autocorrelation plot))\n",
    "\n",
    "# Find the most prominent peak in autocorrelation\n",
    "peaks_w, properties = find_peaks(correlation_normalized.iloc[y_location, :], prominence=0.1)\n",
    "prominent_peak = peaks_w[np.argmax(properties[\"prominences\"])]  # Select the most prominent peak\n",
    "print(\"detected peak indices wavelength\", peaks_w)\n",
    "print(peaks_w[1:])\n",
    "ds_peak_1, = correlation_normalized.columns[[peaks_w[1]]]\n",
    "print(\"space between nodes: \", ds_peak_1)\n",
    "wavelength_MW_1 = ds_peak_1\n",
    "print(\"wavelength 1 (\\u03BCm): \", wavelength_MW_1)\n",
    "\n",
    "# Calculate the width at relative height 0.5\n",
    "widths_half, width_heights_half, left_ips_half, right_ips_half = peak_widths(\n",
    "    correlation_normalized.iloc[y_location, :], [prominent_peak], rel_height=0.5\n",
    ")\n",
    "\n",
    "# Calculate the width at relative height 1.0\n",
    "widths_full, width_heights_full, left_ips_full, right_ips_full = peak_widths(\n",
    "    correlation_normalized.iloc[y_location, :], [prominent_peak], rel_height=1.0\n",
    ")\n",
    "\n",
    "# Print the width values\n",
    "print(f\"Width at 0.5 relative height: {widths_half[0]:.2f} μm\")\n",
    "print(f\"Width at 1.0 relative height: {widths_full[0]:.2f} μm\")\n",
    "\n",
    "\n",
    "# Plot the autocorrelation with the prominent peak and its widths\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(correlation_normalized.columns, correlation_normalized.iloc[1, :], marker='o', linestyle='-', label=\"Autocorrelation\")\n",
    "plt.plot(correlation_normalized.columns[prominent_peak], correlation_normalized.iloc[1, prominent_peak], \"ro\", label=\"Prominent Peak\")\n",
    "\n",
    "# Plot the contour lines for the widths\n",
    "plt.hlines(\n",
    "    width_heights_half, correlation_normalized.columns[int(left_ips_half[0])], correlation_normalized.columns[int(right_ips_half[0])],\n",
    "    color=\"green\", linestyle=\"--\", label=f\"Width at 0.5: {widths_half[0]:.2f} μm\"\n",
    ")\n",
    "plt.hlines(\n",
    "    width_heights_full, correlation_normalized.columns[int(left_ips_full[0])], correlation_normalized.columns[int(right_ips_full[0])],\n",
    "    color=\"purple\", linestyle=\"--\", label=f\"Width at 1.0: {widths_full[0]:.2f} μm\"\n",
    ")\n",
    "plt.axvline(x=ds_peak_1, ymin=0, ymax=1, color='red', linestyle='--')\n",
    "plt.xlabel(\"dx (μm)\")\n",
    "plt.ylabel(\"Autocorrelation\")\n",
    "plt.title(\"Autocorrelation in Space (dt=0) with Peak Widths\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(output_path + \"autocorrelation_with_widths.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "error_wavelength = widths_half[0] / 2  # Using half of the width at 0.5 relative height as the error estimate\n",
    "print(\"Error in wavelength estimation (\\u03BCm): \", error_wavelength)\n",
    "measured_wavelength = ds_peak_1\n",
    "print(\"Measured wavelength (\\u03BCm): \", measured_wavelength)\n",
    "\n",
    "# Quick velocity estimation:\n",
    "# velocity_perceived_1 = ds_peak_1 / dt_peak\n",
    "velocity_perceived_1 = ds_peak_1 * CBF\n",
    "print(\"velocity perceived (\\u03BCm/sec): \", velocity_perceived_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_csv_file(output_path, headers, data):\n",
    "    \"\"\"\n",
    "    Saves fileparameters or results in csv file.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerow(data)\n",
    "    return\n",
    "x_new_cut_start = 0\n",
    "x_new_cut_end   = 80\n",
    "## Save parameters to csv:\n",
    "headers_param = ['file_name','pixel_size', 'fps', 'x_new_cut_start', 'x_new_cut_end', 'CBF', 'CBF error', 'wavelength', 'wavelength error', 'velocity_perceived_1']\n",
    "data_parameters = [file_name, pixel_size, fps, x_new_cut_start, x_new_cut_end, CBF, CBF_error, measured_wavelength, error_wavelength, velocity_perceived_1]\n",
    "save_csv_file(output_path+'parameters-results.csv', headers_param, data_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
